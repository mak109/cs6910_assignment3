{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "016c396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import os\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d75b50f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cec174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f330ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN,GRU,LSTM,Embedding,Input,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dbf4807",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'dakshina_dataset_v1.0'\n",
    "url = 'https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar'\n",
    "if not os.path.exists(filename+'.tar') and not os.path.exists(filename):\n",
    "    filename_tar = wget.download(url)\n",
    "    file = tarfile.open(filename_tar)\n",
    "    print('\\nExtracting files ....')\n",
    "    file.extractall()\n",
    "    file.close()\n",
    "    print('Done')\n",
    "    os.remove(filename_tar)\n",
    "elif not os.path.exists(filename):\n",
    "    filename_tar = filename + '.tar'\n",
    "    file = tarfile.open(filename_tar)\n",
    "    print('\\nExtracting files ....')\n",
    "    file.extractall()\n",
    "    file.close()\n",
    "    print('Done')\n",
    "    os.remove(filename_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ebb6603",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'bn'\n",
    "train_path =  filename+f\"/{lang}/lexicons/{lang}.translit.sampled.train.tsv\"\n",
    "val_path = filename+f\"/{lang}/lexicons/{lang}.translit.sampled.dev.tsv\"\n",
    "test_path = filename+f\"/{lang}/lexicons/{lang}.translit.sampled.test.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8414ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    df = pd.read_csv(path,header=None,sep='\\t')\n",
    "    df.dropna(inplace=True)\n",
    "    input_texts,target_texts = df[1].to_list(),df[0].to_list()\n",
    "    return input_texts,target_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "962458af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text(texts):\n",
    "    characters = set()\n",
    "    for text in texts:\n",
    "        for c in text:\n",
    "            if c not in characters:\n",
    "                characters.add(c)\n",
    "    characters.add(' ')\n",
    "    return sorted(list(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd8bf987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_end_pad(texts):\n",
    "    for i in range(len(texts)):\n",
    "        texts[i] = \"\\t\" + texts[i] + \"\\n\"\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5802cab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_texts,train_target_texts = read_data(train_path)\n",
    "val_input_texts,val_target_texts = read_data(val_path)\n",
    "test_input_texts,test_target_texts = read_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "254339dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_texts = start_end_pad(train_target_texts)\n",
    "val_target_texts = start_end_pad(val_target_texts)\n",
    "test_target_texts = start_end_pad(test_target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff791142",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "input_embedding_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afc360d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_dec_tokens(train_input_texts,train_target_texts,val_input_texts,val_target_texts):\n",
    "    \n",
    "    input_characters = parse_text(train_input_texts + val_input_texts)\n",
    "    target_characters = parse_text(train_target_texts + val_target_texts)\n",
    "    num_encoder_tokens = len(input_characters)\n",
    "    num_decoder_tokens = len(target_characters)\n",
    "    max_encoder_seq_length = max([len(txt) for txt in train_input_texts + val_input_texts])\n",
    "    max_decoder_seq_length = max([len(txt) for txt in train_target_texts + val_target_texts])\n",
    "\n",
    "    print(\"Number of training samples:\", len(train_input_texts))\n",
    "    print(\"Number of validation samples:\", len(val_input_texts))\n",
    "    print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "    print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "    print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "    print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
    "    \n",
    "    input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "    target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "    \n",
    "    return input_token_index,target_token_index,max_encoder_seq_length,max_decoder_seq_length,num_encoder_tokens,num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "372d4d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(input_texts,enc_length,input_token_index,num_encoder_tokens, target_texts,dec_length,target_token_index,num_decoder_tokens):\n",
    "    encoder_input_data = np.zeros(\n",
    "        (len(input_texts), enc_length), dtype=\"float32\"\n",
    "    )\n",
    "    decoder_input_data = np.zeros(\n",
    "            (len(input_texts), dec_length), dtype=\"float32\"\n",
    "        )\n",
    "    decoder_target_data = np.zeros(\n",
    "            (len(input_texts), dec_length, num_decoder_tokens), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "        \n",
    "        for t, char in enumerate(input_text):\n",
    "            encoder_input_data[i, t] = input_token_index[char]\n",
    "        encoder_input_data[i, t + 1 :] = input_token_index[' ']\n",
    "        \n",
    "        for t, char in enumerate(target_text):\n",
    "                # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "            decoder_input_data[i, t] = target_token_index[char]\n",
    "            if t > 0:\n",
    "                    # decoder_target_data will be ahead by one timestep\n",
    "                    # and will not include the start character.\n",
    "                decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "        decoder_input_data[i, t + 1 :] = target_token_index[' ']\n",
    "        decoder_target_data[i, t:, target_token_index[' ']] = 1.0\n",
    "    return encoder_input_data,decoder_input_data,decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51ac3146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 94543\n",
      "Number of validation samples: 9279\n",
      "Number of unique input tokens: 27\n",
      "Number of unique output tokens: 63\n",
      "Max sequence length for inputs: 22\n",
      "Max sequence length for outputs: 24\n"
     ]
    }
   ],
   "source": [
    "input_token_index,target_token_index,max_encoder_seq_length,max_decoder_seq_length,num_encoder_tokens,num_decoder_tokens = enc_dec_tokens(train_input_texts,train_target_texts,val_input_texts,val_target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a1f066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoder_input,train_decoder_input,train_decoder_target = data_processing(train_input_texts,max_encoder_seq_length,input_token_index,num_encoder_tokens, train_target_texts,max_decoder_seq_length,target_token_index,num_decoder_tokens)\n",
    "val_encoder_input,val_decoder_input,val_decoder_target = data_processing(val_input_texts,max_encoder_seq_length,input_token_index,num_encoder_tokens, val_target_texts,max_decoder_seq_length,target_token_index,num_decoder_tokens)\n",
    "test_encoder_input,test_decoder_input,test_decoder_target = data_processing(test_input_texts,max_encoder_seq_length,input_token_index,num_encoder_tokens, test_target_texts,max_decoder_seq_length,target_token_index,num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4838e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(num_encoder_tokens,num_decoder_tokens,input_embedding_size=16,num_enc_layers=1,num_dec_layers=1,hidden_layer_size=64,cell_type='LSTM',dropout=0,r_dropout=0,cell_activation='tanh'):\n",
    "    cell = {\n",
    "        'RNN':SimpleRNN,\n",
    "        'LSTM':LSTM,\n",
    "        'GRU':GRU\n",
    "    }\n",
    "    encoder_input = Input(shape=(None,),name='input_1')\n",
    "    encoder_input_embedding = Embedding(num_encoder_tokens,input_embedding_size,name='embedding_1')(encoder_input)\n",
    "    \n",
    "    encoder_sequences, *encoder_state = cell[cell_type](hidden_layer_size,activation=cell_activation,return_sequences=True,return_state=True,dropout=dropout,recurrent_dropout=r_dropout,name=\"encoder_1\")(encoder_input_embedding)\n",
    "    \n",
    "    for i in range(1,num_enc_layers):\n",
    "        encoder_sequences, *encoder_state = cell[cell_type](hidden_layer_size,activation=cell_activation,return_sequences=True,return_state=True,dropout=dropout,recurrent_dropout=r_dropout,name=f\"encoder_{i+1}\")(encoder_sequences)\n",
    "        \n",
    "    decoder_input = Input(shape=(None,),name='input_2')\n",
    "    decoder_input_embedding = Embedding(num_decoder_tokens,input_embedding_size,name='embedding_2')(decoder_input)\n",
    "    \n",
    "    decoder_sequences, *decoder_state = cell[cell_type](hidden_layer_size,activation=cell_activation,return_sequences=True,return_state=True,dropout=dropout,recurrent_dropout=r_dropout,name=\"decoder_1\")(decoder_input_embedding ,initial_state=encoder_state)\n",
    "    \n",
    "    for i in range(1,num_dec_layers):\n",
    "        decoder_sequences, *decoder_state = cell[cell_type](hidden_layer_size,activation=cell_activation,return_sequences=True,return_state=True,dropout=dropout,recurrent_dropout=r_dropout,name=f\"decoder_{i+1}\")(decoder_sequences ,initial_state=encoder_state)\n",
    "    \n",
    "    decoder_dense = Dense(num_decoder_tokens,activation=\"softmax\",name=\"dense_1\")(decoder_sequences)\n",
    "    \n",
    "    model = keras.Model([encoder_input,decoder_input],decoder_dense)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af61f7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = make_model(num_encoder_tokens,num_decoder_tokens,input_embedding_size=32,hidden_layer_size=128,num_enc_layers=2,num_dec_layers=2,cell_type='LSTM')\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(\n",
    "    [train_encoder_input, train_decoder_input],\n",
    "    train_decoder_target,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=([val_encoder_input, val_decoder_input],val_decoder_target),\n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4e8331c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x366d2e580> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x366d47220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x333be7550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x333be0520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# model.save(\"s2s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed63c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ff6aaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inference_model(model):\n",
    "    # Calculating number of layers in encoder and decoder\n",
    "    num_enc_layers, num_dec_layers = 0, 0\n",
    "    for layer in model.layers:\n",
    "        num_enc_layers += layer.name.startswith('encoder')\n",
    "        num_dec_layers += layer.name.startswith('decoder')\n",
    "\n",
    "    # Encoder input\n",
    "    encoder_input = model.input[0]      # Input_1\n",
    "    # Encoder cell final layer\n",
    "    encoder_cell = model.get_layer(\"encoder_\"+str(num_enc_layers))\n",
    "    encoder_type = encoder_cell.__class__.__name__\n",
    "    encoder_seq, *encoder_state = encoder_cell.output\n",
    "    # Encoder model\n",
    "    encoder_model = keras.Model(encoder_input, encoder_state)\n",
    "\n",
    "    # Decoder input\n",
    "    decoder_input = model.input[1]      # Input_2\n",
    "    decoder_input_embedding = model.get_layer(\"embedding_2\")(decoder_input)\n",
    "    decoder_sequences = decoder_input_embedding\n",
    "    # Inputs to decoder layers' initial states\n",
    "    decoder_states, decoder_state_inputs = [], []\n",
    "    for i in range(1, num_dec_layers+1):\n",
    "        if encoder_type == 'LSTM':\n",
    "            decoder_state_input = [Input(shape=(encoder_state[0].shape[1],), name=\"input_\"+str(2*i+1)), \n",
    "                                   Input(shape=(encoder_state[1].shape[1],), name=\"input_\"+str(2*i+2))]\n",
    "        else:\n",
    "            decoder_state_input = [Input(shape=(encoder_state[0].shape[1],), name=\"input_\"+str(i+2))]\n",
    "\n",
    "        decoder_cell = model.get_layer(\"decoder_\"+str(i))\n",
    "        decoder_sequences, *decoder_state = decoder_cell(decoder_sequences, initial_state=decoder_state_input)\n",
    "        decoder_states += decoder_state\n",
    "        decoder_state_inputs += decoder_state_input\n",
    "\n",
    "    # Softmax FC layer\n",
    "    decoder_dense = model.get_layer(\"dense_1\")\n",
    "    decoder_dense_output = decoder_dense(decoder_sequences)\n",
    "\n",
    "    # Decoder model\n",
    "    decoder_model = keras.Model(\n",
    "        [decoder_input] + decoder_state_inputs, [decoder_dense_output] + decoder_states\n",
    "    )\n",
    "\n",
    "    return encoder_model, decoder_model, num_enc_layers, num_dec_layers\n",
    "\n",
    "\n",
    "def convert_to_word(predictions, target_token_index, reverse_target_char_index = None):\n",
    "    # Function to return the predictions after cutting the END_CHAR and BLANK_CHAR s at the end.\n",
    "    # If char_dec == None, the predictions are in the form of decoded string, otherwise as list of integers\n",
    "    no_samples = len(predictions) if type(predictions) is list else predictions.shape[0]\n",
    "    pred_words = ['' for _ in range(no_samples)]\n",
    "    for i, pred_list in enumerate(predictions):\n",
    "        for l in pred_list:\n",
    "            # Stop word : END_CHAR\n",
    "            if l == target_token_index['\\n']:\n",
    "                break\n",
    "            pred_words[i] += reverse_target_char_index[l] if reverse_target_char_index is not None else l\n",
    "    \n",
    "    return pred_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4f8a58d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_decoder_infer(model,input_seqs,max_decoder_seq_length,K=1,target_seqs=None,starting_char=0,batch_size=64):\n",
    "    \n",
    "    reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "    reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "    encoder_model,decoder_model,num_enc_layers,num_dec_layers=create_inference_model(model)\n",
    "    encoder_output = encoder_model.predict(input_seqs,batch_size=batch_size)\n",
    "    encoder_output = encoder_output if type(encoder_output) is list else [encoder_output]\n",
    "    \n",
    "    num_samples = input_seqs.shape[0]\n",
    "    \n",
    "    final_outputs = np.zeros((num_samples,K,max_decoder_seq_length),dtype=np.int32)\n",
    "    \n",
    "    final_errors = np.zeros((num_samples,K))\n",
    "    \n",
    "    decoder_k_inputs = np.zeros((num_samples,1,1))\n",
    "    decoder_k_inputs[:, :, 0] = starting_char\n",
    "    \n",
    "    decoder_k_out = [[(0, [])] for _ in range(num_samples)]\n",
    "    \n",
    "    errors = [[0] for _ in range(num_samples)]\n",
    "    \n",
    "    states = [encoder_output*num_dec_layers]\n",
    "    \n",
    "    for idx in range(max_decoder_seq_length):\n",
    "        all_k_beams = [[] for _ in range(num_samples)]\n",
    "        all_decoder_states = [[] for _ in range(num_samples)]\n",
    "        all_errors = [[] for _ in range(num_samples)]\n",
    "        \n",
    "        for k in range(len(decoder_k_out[0])):\n",
    "            decoder_output, *decoder_states = decoder_model.predict([decoder_k_inputs[:,k]] + states[k],batch_size=batch_size)\n",
    "            top_k = np.argsort(decoder_output[:,-1,:],axis=-1)[:,-K:]\n",
    "            for n in range(num_samples):\n",
    "                all_k_beams[n]+= [(decoder_k_out[n][k][0] + np.log(decoder_output[n, -1, top_k[n][i]]),decoder_k_out[n][k][1] + [top_k[n][i]]) for i in range(K)]\n",
    "                if target_seqs is not None:\n",
    "                    all_errors[n] += [errors[n][k] - np.log(decoder_output[n,-1,target_seqs[n,idx]])]*K\n",
    "                all_decoder_states[n] += [[decoder_state[n:n+1] for decoder_state in decoder_states]] * K\n",
    "        sorted_index = list(range(len(all_k_beams[0])))\n",
    "        sorted_index = [sorted(sorted_index,key = lambda ix: all_k_beams[n][ix][0])[-K:][::-1] for n in range(num_samples)]\n",
    "        \n",
    "        decoder_k_out = [[all_k_beams[n][index] for index in sorted_index[n]] for n in range(num_samples)]\n",
    "        \n",
    "        decoder_k_inputs = np.array([[all_k_beams[n][index][-1] for index in sorted_index[n]] for n in range(num_samples)])\n",
    "        \n",
    "        states = [all_decoder_states[0][index] for index in sorted_index[0]]\n",
    "        \n",
    "        for n in range(1,num_samples):\n",
    "            states = [[np.concatenate((states[i][j],all_decoder_states[n][index][j])) for j in range(len(all_decoder_states[n][index]))] for i,index in  enumerate(sorted_index[n])]\n",
    "        if target_seqs is not None:\n",
    "            errors = [[all_errors[n][index] for index in sorted_index[n]] for n in range(num_samples)]\n",
    "    final_outputs = np.array([[decoder_k_out[n][i][1] for i in range(K)] for n in range(num_samples)])\n",
    "    if target_seqs is not None:\n",
    "        final_errors = np.array(errors)/max_decoder_seq_length\n",
    "    return final_outputs,final_errors,np.array(states)\n",
    "def calc_metrics(k_outputs, target_seqs,target_token_index,reverse_target_char_index,k_errors=None,exact_word=True,display=False):\n",
    "    matches = np.mean(k_outputs == np.repeat(target_seqs.reshape((target_seqs.shape[0],1,target_seqs.shape[1])),k_outputs.shape[1],axis=1),axis=-1)\n",
    "    best_k = np.argmax(matches,axis=-1)\n",
    "    best_index = (tuple(range(best_k.shape[0])),tuple(best_k))\n",
    "    accuracy = np.mean(matches[best_index])\n",
    "    k_predictions = list()\n",
    "    loss = None\n",
    "    if k_errors is not None:\n",
    "        loss = np.mean(k_errors[best_index])\n",
    "    if exact_word:\n",
    "        equal = [0] * k_outputs.shape[0]\n",
    "        true_out = convert_to_word(target_seqs,target_token_index,reverse_target_char_index)\n",
    "        for k in range(k_outputs.shape[1]):\n",
    "            pred_out = convert_to_word(k_outputs[:,k], target_token_index,reverse_target_char_index)\n",
    "            equal = [equal[i] or (pred_out[i] == true_out[i]) for i in range(k_outputs.shape[0])]\n",
    "            if display==True:\n",
    "                k_predictions.append(pred_out)\n",
    "        exact_accuracy = np.mean(equal)\n",
    "        if display==True:\n",
    "            return accuracy,exact_accuracy,loss,true_out,k_predictions\n",
    "        return accuracy,exact_accuracy,loss\n",
    "    return accuracy,loss\n",
    "def beam_decoder(model,input_seqs,target_seqs_onehot,max_decoder_seq_length,target_token_index,reverse_target_char_index,K=1,model_batch_size=64,infer_batch_size=512,exact_word=True,return_outputs=False,return_states=False,display=False):\n",
    "    target_seqs = np.argmax(target_seqs_onehot,axis=-1)\n",
    "    k_outputs,k_errors,k_states=None,None,None\n",
    "    for i in range(0,input_seqs.shape[0],infer_batch_size):\n",
    "        tmp_k_outputs,tmp_k_errors,tmp_k_states = beam_decoder_infer(model,input_seqs[i:i+infer_batch_size],max_decoder_seq_length,K,target_seqs[i:i+infer_batch_size],target_token_index['\\t'],model_batch_size)\n",
    "        \n",
    "        if k_errors is None:\n",
    "            k_outputs,k_errors,k_states = tmp_k_outputs,tmp_k_errors,tmp_k_states\n",
    "        else:\n",
    "            k_outputs = np.concatenate((k_outputs,tmp_k_outputs))\n",
    "            k_errors = np.concatenate((k_errors,tmp_k_errors))\n",
    "            k_states = np.concatenate((k_states,tmp_k_states),axis=2)\n",
    "    return_elements = []\n",
    "    if return_outputs:\n",
    "        return_elements += [k_outputs]\n",
    "    if return_states:\n",
    "        return_elements += [k_states]\n",
    "    if len(return_elements) > 0:\n",
    "        return calc_metrics(k_outputs,target_seqs,target_token_index,reverse_target_char_index,k_errors,exact_word,display) + tuple(return_elements)\n",
    "    return calc_metrics(k_outputs,target_seqs,target_token_index,reverse_target_char_index,k_errors,exact_word,display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3d6c77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 19:16:53.429678: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:16:53.505983: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:16:53.633195: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:16:53.964944: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:16:54.038858: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:16:54.115272: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:16:54.430384: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:16:54.502138: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:16:54.576915: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:16:55.362286: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:16:55.436306: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:16:55.517647: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:16:59.566770: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:16:59.640889: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:16:59.743163: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:00.049368: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:00.129672: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:00.201367: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:00.493160: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:00.562777: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:00.633569: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:00.940147: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:01.013701: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:01.086694: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:05.068647: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:05.138247: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:05.233602: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:05.544758: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:05.611680: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:05.683990: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:05.996273: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:06.066048: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:06.132180: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:06.435666: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:06.510633: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:06.592271: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:11.097784: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:11.173187: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:11.268885: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:11.587976: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:11.656063: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:11.728332: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:12.032552: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:12.104080: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:12.175837: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:12.501310: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:12.575048: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:12.659326: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:16.725742: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:16.796742: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:16.925955: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:17.276579: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:17.348072: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:17.448276: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 19:17:17.794285: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:17.866802: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:17.938055: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:18.257737: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:18.333000: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:18.413640: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:23.034565: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:23.107815: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:23.246181: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:23.595662: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:23.678450: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:23.752679: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:24.070443: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:24.149856: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:24.255871: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:24.616210: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:24.690682: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:24.771132: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:29.000857: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:29.069435: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:29.163490: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:29.497411: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:29.565323: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:29.634798: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:29.925593: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:30.003247: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:30.104515: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:30.444466: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:30.518316: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:30.605353: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:34.731736: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:34.818017: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:34.913316: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:35.709442: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:35.806077: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:35.880432: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:36.276802: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:36.349715: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:36.420025: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:36.741651: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:36.813918: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:36.887767: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:41.169168: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:41.239530: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:41.369493: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:41.713355: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:41.779981: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:41.848423: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:42.153334: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:42.237135: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:42.337424: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:42.710742: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:42.783372: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:42.864593: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 19:17:47.219105: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:47.285667: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:47.378376: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:47.708588: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:47.780283: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:47.881233: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:48.605590: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:48.683600: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:48.758835: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:49.113414: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:49.187410: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:49.266611: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:53.612209: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:53.685904: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:53.821949: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:54.193937: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:54.263664: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:54.330198: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:54.649422: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:54.725681: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:54.792525: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:55.106380: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:55.179062: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:55.254677: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:59.648527: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:59.723583: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:17:59.861160: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:00.243700: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:00.317908: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:00.419484: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:00.775618: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:00.849752: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:00.915198: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:01.242803: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:01.321570: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:01.437794: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:06.295926: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:06.362975: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:06.452321: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:06.777601: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:06.844236: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:06.908647: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:07.201018: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:07.308866: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:07.417033: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:07.752966: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:07.845761: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:07.964503: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:12.452337: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:12.524765: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:12.661204: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:13.071207: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:13.139540: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:13.207406: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 19:18:13.524676: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:13.603106: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:13.706804: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:14.080944: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:14.153015: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:14.229129: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:19.291358: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:19.375727: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:19.523598: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:19.947343: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:20.022089: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:20.121457: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:20.488603: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:20.572315: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:20.675451: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:21.061272: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:21.143437: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:21.261872: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:26.063358: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:26.135167: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:26.270653: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:26.635729: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:26.711521: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:26.819065: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:27.174747: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:27.252793: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:27.357820: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:27.764430: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:27.836581: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:27.911102: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:32.627026: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:32.698780: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:32.839400: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:33.575484: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:33.659878: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:33.769016: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:34.168160: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:34.244861: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:34.345410: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:34.703793: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:34.783112: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:34.905322: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:39.757749: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:39.836277: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:39.983443: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:40.373512: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:40.447219: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:40.561781: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:40.945705: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:41.022915: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:41.126068: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:41.513720: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:41.610528: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 19:18:41.754443: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:46.507695: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:46.585186: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:46.716410: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:46.991868: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:47.070016: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:47.172385: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:47.412901: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:47.486812: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:47.557367: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:47.808750: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:47.888475: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 19:18:48.001965: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "outs = beam_decoder(model,val_encoder_input,val_decoder_target,max_decoder_seq_length,target_token_index,reverse_target_char_index,display=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c3019fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', ''], dtype='<U17')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(outs[-2])[np.array(outs[-1][0]) == np.array(outs[-2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "286c59d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aap', 'ap', 'aamor', 'amar', 'ammor', 'amoor', 'amor', 'aarke',\n",
       "       'alsaar', 'alsaara', 'alsar', 'alsara', 'asor', 'ase', 'ashe',\n",
       "       'uthe', 'uthhe', 'udar', 'udor', 'ul', 'ula', 'uul', 'ekar',\n",
       "       'ghoor', 'ghur', 'jess', 'zess', 'dor', 'nirau', 'niro', 'pra',\n",
       "       'fall', 'bon', 'boney', 'baugey', 'bhor', 'vor', 'sur', 'hailo',\n",
       "       'hoeel', 'hoil', 'hoila', 'hoilo', 'huka'], dtype='<U20')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(val_input_texts)[np.array(outs[-1][0]) == np.array(outs[-2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de56242a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 18:59:32.399478: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-20 18:59:32.399731: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    }
   ],
   "source": [
    "# Define sampling models\n",
    "# Restore the model and construct the encoder and decoder.\n",
    "model = keras.models.load_model(\"s2s\")\n",
    "\n",
    "# encoder_inputs = model.input[0]  # input_1\n",
    "# encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
    "# encoder_states = [state_h_enc, state_c_enc]\n",
    "# encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# decoder_inputs = model.input[1]  # input_2\n",
    "# decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
    "# decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
    "# decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "# decoder_lstm = model.layers[3]\n",
    "# decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "#     decoder_inputs, initial_state=decoder_states_inputs\n",
    "# )\n",
    "# decoder_states = [state_h_dec, state_c_dec]\n",
    "# decoder_dense = model.layers[4]\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)\n",
    "# decoder_model = keras.Model(\n",
    "#     [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    "# )\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "# encoder_model,decoder_model,num_enc_layers,num_dec_layers=create_inference_model(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22b44db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '\\t',\n",
       " 1: '\\n',\n",
       " 2: ' ',\n",
       " 3: '',\n",
       " 4: '',\n",
       " 5: '',\n",
       " 6: '',\n",
       " 7: '',\n",
       " 8: '',\n",
       " 9: '',\n",
       " 10: '',\n",
       " 11: '',\n",
       " 12: '',\n",
       " 13: '',\n",
       " 14: '',\n",
       " 15: '',\n",
       " 16: '',\n",
       " 17: '',\n",
       " 18: '',\n",
       " 19: '',\n",
       " 20: '',\n",
       " 21: '',\n",
       " 22: '',\n",
       " 23: '',\n",
       " 24: '',\n",
       " 25: '',\n",
       " 26: '',\n",
       " 27: '',\n",
       " 28: '',\n",
       " 29: '',\n",
       " 30: '',\n",
       " 31: '',\n",
       " 32: '',\n",
       " 33: '',\n",
       " 34: '',\n",
       " 35: '',\n",
       " 36: '',\n",
       " 37: '',\n",
       " 38: '',\n",
       " 39: '',\n",
       " 40: '',\n",
       " 41: '',\n",
       " 42: '',\n",
       " 43: '',\n",
       " 44: '',\n",
       " 45: '',\n",
       " 46: '',\n",
       " 47: '',\n",
       " 48: '',\n",
       " 49: '',\n",
       " 50: '',\n",
       " 51: '',\n",
       " 52: '',\n",
       " 53: '',\n",
       " 54: '',\n",
       " 55: '',\n",
       " 56: '',\n",
       " 57: '',\n",
       " 58: '',\n",
       " 59: '',\n",
       " 60: '',\n",
       " 61: '',\n",
       " 62: ''}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_target_char_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6934dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4], [4], [4], [4]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[4]]*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cf5c702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "#     print(states_value)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, 1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0,0,0] = target_token_index['\\t']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = True\n",
    "    decoded_sentence = \"\"\n",
    "    states = [states_value]*num_dec_layers\n",
    "        # Sample a token\n",
    "#     sampled_token_indices = np.argmax(output_tokens[0,:,:],axis=1)\n",
    "    while stop_condition:\n",
    "        output_tokens, *decoder_states = decoder_model.predict([target_seq] + states)\n",
    "        print(output_tokens.shape)\n",
    "        idx = np.argmax(output_tokens[0,-1,:])\n",
    "        c = reverse_target_char_index[idx]\n",
    "        decoded_sentence += c\n",
    "        if(c=='\\n' or len(decoded_sentence)>max_decoder_seq_length):\n",
    "            stop_condition = False\n",
    "        target_seq = np.zeros((1, 1,num_decoder_tokens))\n",
    "        target_seq[0,0,0] = target_token_index[c]\n",
    "        states = decoder_states\n",
    "#         beam_samples = beam_search_decoder(output_tokens[0],10)\n",
    "#         results = list()\n",
    "#         for sampled_token_indices,score in beam_samples:\n",
    "#             for i in sampled_token_indices:\n",
    "#                 c = reverse_target_char_index[i]\n",
    "#                 if(c=='\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "#                     stop_condition = True\n",
    "#                 decoded_sentence += c\n",
    "\n",
    "#                 # Exit condition: either hit max length\n",
    "#                 # or find stop character.\n",
    "#             results.append(decoded_sentence)\n",
    "#             decoded_sentence = \"\"\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1f35980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encoder_input[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65ab57e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, None, 32)     2016        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " decoder_1 (LSTM)               [(None, None, 128),  82432       ['embedding_2[1][0]',            \n",
      "                                 (None, 128),                     'input_3[0][0]',                \n",
      "                                 (None, 128)]                     'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " decoder_2 (LSTM)               [(None, None, 128),  131584      ['decoder_1[1][0]',              \n",
      "                                 (None, 128),                     'input_5[0][0]',                \n",
      "                                 (None, 128)]                     'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, None, 63)     8127        ['decoder_2[1][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 224,159\n",
      "Trainable params: 224,159\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe773fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ae5ac4fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1, None).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/homebrew/Caskroom/miniforge/base/envs/mak/lib/python3.8/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/opt/homebrew/Caskroom/miniforge/base/envs/mak/lib/python3.8/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/homebrew/Caskroom/miniforge/base/envs/mak/lib/python3.8/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/opt/homebrew/Caskroom/miniforge/base/envs/mak/lib/python3.8/site-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/opt/homebrew/Caskroom/miniforge/base/envs/mak/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/homebrew/Caskroom/miniforge/base/envs/mak/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 213, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"model_1\" (type Functional).\n    \n    Input 0 of layer \"decoder_1\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 1, None, 32)\n    \n    Call arguments received:\n       inputs=('tf.Tensor(shape=(None, 1, None), dtype=float32)', ('tf.Tensor(shape=(None, 128), dtype=float32)', 'tf.Tensor(shape=(None, 128), dtype=float32)'), ('tf.Tensor(shape=(None, 128), dtype=float32)', 'tf.Tensor(shape=(None, 128), dtype=float32)'))\n       training=False\n       mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seq_index \u001b[38;5;129;01min\u001b[39;00m rand_indices:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Take one sequence (part of the training set)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# for trying out decoding.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     input_seq \u001b[38;5;241m=\u001b[39m train_encoder_input[seq_index,:]\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m----> 6\u001b[0m     decoded_sentences \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput sentence:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_input_texts[seq_index])\n",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# Sample a token\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#     sampled_token_indices = np.argmax(output_tokens[0,:,:],axis=1)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m stop_condition:\n\u001b[0;32m---> 18\u001b[0m         output_tokens, \u001b[38;5;241m*\u001b[39mdecoder_states \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_seq\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28mprint\u001b[39m(output_tokens\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     20\u001b[0m         idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(output_tokens[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:])\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mak/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mak/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/homebrew/Caskroom/miniforge/base/envs/mak/lib/python3.8/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/opt/homebrew/Caskroom/miniforge/base/envs/mak/lib/python3.8/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/homebrew/Caskroom/miniforge/base/envs/mak/lib/python3.8/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/opt/homebrew/Caskroom/miniforge/base/envs/mak/lib/python3.8/site-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/opt/homebrew/Caskroom/miniforge/base/envs/mak/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/homebrew/Caskroom/miniforge/base/envs/mak/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 213, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"model_1\" (type Functional).\n    \n    Input 0 of layer \"decoder_1\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 1, None, 32)\n    \n    Call arguments received:\n       inputs=('tf.Tensor(shape=(None, 1, None), dtype=float32)', ('tf.Tensor(shape=(None, 128), dtype=float32)', 'tf.Tensor(shape=(None, 128), dtype=float32)'), ('tf.Tensor(shape=(None, 128), dtype=float32)', 'tf.Tensor(shape=(None, 128), dtype=float32)'))\n       training=False\n       mask=None\n"
     ]
    }
   ],
   "source": [
    "rand_indices = random.sample(range(train_encoder_input.shape[0]),20)\n",
    "for seq_index in rand_indices:\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = train_encoder_input[seq_index,:].reshape((1,-1))\n",
    "    decoded_sentences = decode_sequence(input_seq)\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", train_input_texts[seq_index])\n",
    "#     print(\"Target sentence :\",train_target_texts[seq_index])\n",
    "    print(\"Decoded sentence:\", decoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "62c75b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_k_out = [[(0, [1,2])] for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "24847243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(decoder_k_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56d267c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "[[4, 0, 4, 0, 4, 0, 4, 0, 4, 0], 6.931471805599453]\n",
      "[[4, 0, 4, 0, 4, 0, 4, 0, 4, 1], 7.154615356913663]\n",
      "[[4, 0, 4, 0, 4, 0, 4, 0, 3, 0], 7.154615356913663]\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "\n",
    "# beam search\n",
    "def beam_search_decoder(data, k):\n",
    "    sequences = [[list(), 0.0]]\n",
    "    # walk over each step in sequence\n",
    "    for row in data:\n",
    "        all_candidates = list()\n",
    "        # expand each current candidate\n",
    "        print(len(sequences))\n",
    "        for i in range(len(sequences)):\n",
    "            seq, score = sequences[i]\n",
    "            for j in range(len(row)):\n",
    "                candidate = [seq + [j], score - log(row[j])]\n",
    "#                 print(candidate)\n",
    "                all_candidates.append(candidate)\n",
    "        # order all candidates by score\n",
    "        ordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
    "        # select k best\n",
    "        sequences = ordered[:k]\n",
    "    return sequences\n",
    "\n",
    "# define a sequence of 10 words over a vocab of 5 words\n",
    "data = [[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "\t\t[0.5, 0.4, 0.3, 0.2, 0.1],\n",
    "\t\t[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "\t\t[0.5, 0.4, 0.3, 0.2, 0.1],\n",
    "\t\t[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "\t\t[0.5, 0.4, 0.3, 0.2, 0.1],\n",
    "\t\t[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "\t\t[0.5, 0.4, 0.3, 0.2, 0.1],\n",
    "\t\t[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "\t\t[0.5, 0.4, 0.3, 0.2, 0.1]]\n",
    "data = array(data)\n",
    "# decode sequence\n",
    "result = beam_search_decoder(data, 3)\n",
    "# print result\n",
    "for seq in result:\n",
    "\tprint(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de62f43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
