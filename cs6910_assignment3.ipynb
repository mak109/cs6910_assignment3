{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wget","metadata":{"execution":{"iopub.status.busy":"2022-05-02T04:53:25.474062Z","iopub.execute_input":"2022-05-02T04:53:25.47439Z","iopub.status.idle":"2022-05-02T04:53:37.773895Z","shell.execute_reply.started":"2022-05-02T04:53:25.474307Z","shell.execute_reply":"2022-05-02T04:53:37.772888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wget\nimport os\nimport tarfile","metadata":{"execution":{"iopub.status.busy":"2022-05-02T04:54:18.734905Z","iopub.execute_input":"2022-05-02T04:54:18.735171Z","iopub.status.idle":"2022-05-02T04:54:18.746807Z","shell.execute_reply.started":"2022-05-02T04:54:18.735138Z","shell.execute_reply":"2022-05-02T04:54:18.746149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-05-02T04:54:20.411719Z","iopub.execute_input":"2022-05-02T04:54:20.412289Z","iopub.status.idle":"2022-05-02T04:54:20.415742Z","shell.execute_reply.started":"2022-05-02T04:54:20.412251Z","shell.execute_reply":"2022-05-02T04:54:20.414961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2022-05-02T04:54:21.908981Z","iopub.execute_input":"2022-05-02T04:54:21.909418Z","iopub.status.idle":"2022-05-02T04:54:25.956177Z","shell.execute_reply.started":"2022-05-02T04:54:21.909383Z","shell.execute_reply":"2022-05-02T04:54:25.955371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import SimpleRNN,GRU,LSTM,Embedding,Input,Dense","metadata":{"execution":{"iopub.status.busy":"2022-05-02T04:54:25.957828Z","iopub.execute_input":"2022-05-02T04:54:25.958208Z","iopub.status.idle":"2022-05-02T04:54:26.782509Z","shell.execute_reply.started":"2022-05-02T04:54:25.958171Z","shell.execute_reply":"2022-05-02T04:54:26.781781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = 'dakshina_dataset_v1.0'\nurl = 'https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar'\nif not os.path.exists(filename+'.tar') and not os.path.exists(filename):\n    filename_tar = wget.download(url)\n    file = tarfile.open(filename_tar)\n    print('\\nExtracting files ....')\n    file.extractall()\n    file.close()\n    print('Done')\n    os.remove(filename_tar)\nelif not os.path.exists(filename):\n    filename_tar = filename + '.tar'\n    file = tarfile.open(filename_tar)\n    print('\\nExtracting files ....')\n    file.extractall()\n    file.close()\n    print('Done')\n    os.remove(filename_tar)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T04:54:26.783757Z","iopub.execute_input":"2022-05-02T04:54:26.783979Z","iopub.status.idle":"2022-05-02T04:54:49.975682Z","shell.execute_reply.started":"2022-05-02T04:54:26.783948Z","shell.execute_reply":"2022-05-02T04:54:49.974892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lang = 'bn'\ntrain_path =  filename+f\"/{lang}/lexicons/{lang}.translit.sampled.train.tsv\"\nval_path = filename+f\"/{lang}/lexicons/{lang}.translit.sampled.dev.tsv\"\ntest_path = filename+f\"/{lang}/lexicons/{lang}.translit.sampled.test.tsv\"","metadata":{"execution":{"iopub.status.busy":"2022-05-02T04:58:16.365438Z","iopub.execute_input":"2022-05-02T04:58:16.366005Z","iopub.status.idle":"2022-05-02T04:58:16.370967Z","shell.execute_reply.started":"2022-05-02T04:58:16.365965Z","shell.execute_reply":"2022-05-02T04:58:16.370147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_data(path):\n    df = pd.read_csv(path,header=None,sep='\\t')\n    df.fillna(\"NaN\",inplace=True)\n    input_texts,target_texts = df[1].to_list(),df[0].to_list()\n    return input_texts,target_texts","metadata":{"execution":{"iopub.status.busy":"2022-05-02T04:58:18.153825Z","iopub.execute_input":"2022-05-02T04:58:18.154077Z","iopub.status.idle":"2022-05-02T04:58:18.158608Z","shell.execute_reply.started":"2022-05-02T04:58:18.154049Z","shell.execute_reply":"2022-05-02T04:58:18.157924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parse_text(texts):\n    characters = set()\n    for text in texts:\n        for c in text:\n            if c not in characters:\n                characters.add(c)\n    characters.add(' ')\n    return sorted(list(characters))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T04:58:19.457824Z","iopub.execute_input":"2022-05-02T04:58:19.45868Z","iopub.status.idle":"2022-05-02T04:58:19.463231Z","shell.execute_reply.started":"2022-05-02T04:58:19.45864Z","shell.execute_reply":"2022-05-02T04:58:19.462281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def start_end_pad(texts):\n    for i in range(len(texts)):\n        texts[i] = \"\\t\" + texts[i] + \"\\n\"\n    return texts","metadata":{"execution":{"iopub.status.busy":"2022-05-02T04:58:20.891297Z","iopub.execute_input":"2022-05-02T04:58:20.891838Z","iopub.status.idle":"2022-05-02T04:58:20.896527Z","shell.execute_reply.started":"2022-05-02T04:58:20.891798Z","shell.execute_reply":"2022-05-02T04:58:20.895734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input_texts,train_target_texts = read_data(train_path)\nval_input_texts,val_target_texts = read_data(val_path)\ntest_input_texts,test_target_texts = read_data(test_path)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T04:58:27.017063Z","iopub.execute_input":"2022-05-02T04:58:27.017681Z","iopub.status.idle":"2022-05-02T04:58:27.168087Z","shell.execute_reply.started":"2022-05-02T04:58:27.017641Z","shell.execute_reply":"2022-05-02T04:58:27.167408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_target_texts = start_end_pad(train_target_texts)\nval_target_texts = start_end_pad(val_target_texts)\ntest_target_texts = start_end_pad(test_target_texts)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T04:58:29.12895Z","iopub.execute_input":"2022-05-02T04:58:29.129206Z","iopub.status.idle":"2022-05-02T04:58:29.166789Z","shell.execute_reply.started":"2022-05-02T04:58:29.129178Z","shell.execute_reply":"2022-05-02T04:58:29.166108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config_ = {\n    \"learning_rate\": 1e-3,                                      # Learning rate in gradient descent\n    \"epochs\": 20,                                               # Number of epochs to train the model   \n    \"optimizer\": 'adam',                                        # Gradient descent algorithm used for the parameter updation\n    \"batch_size\": 64,                                           # Batch size used for the optimizer\n    \"loss_function\": 'categorical_crossentropy',                # Loss function used in the optimizer                                                                      # Name of dataset\n    \"input_embedding_size\": 256,                                        # Size of input embedding layer\n    \"num_enc_layers\": 2,                                         # Number of layers in the encoder\n    \"num_dec_layers\": 5,                                         # Number of layers in the decoder\n    \"hidden_layer_size\": 768,                                      # Size of hidden layer\n    \"dropout\" : 0.30,\n    'r_dropout':0.30,# Value of dropout used in the normal and recurrent dropout\n    \"cell_type\": 'GRU',                                         # Type of cell used in the encoder and decoder ('RNN' or 'GRU' or 'LSTM')\n    \"beam_width\": 1                                          # Beam width used in beam decoder                                        \n}","metadata":{"execution":{"iopub.status.busy":"2022-05-02T04:58:31.691451Z","iopub.execute_input":"2022-05-02T04:58:31.692268Z","iopub.status.idle":"2022-05-02T04:58:31.698195Z","shell.execute_reply.started":"2022-05-02T04:58:31.692226Z","shell.execute_reply":"2022-05-02T04:58:31.697301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def enc_dec_tokens(train_input_texts,train_target_texts,val_input_texts,val_target_texts):\n    \n    input_characters = parse_text(train_input_texts + val_input_texts)\n    target_characters = parse_text(train_target_texts + val_target_texts)\n    num_encoder_tokens = len(input_characters)\n    num_decoder_tokens = len(target_characters)\n    max_encoder_seq_length = max([len(txt) for txt in train_input_texts + val_input_texts])\n    max_decoder_seq_length = max([len(txt) for txt in train_target_texts + val_target_texts])\n\n    print(\"Number of training samples:\", len(train_input_texts))\n    print(\"Number of validation samples:\", len(val_input_texts))\n    print(\"Number of unique input tokens:\", num_encoder_tokens)\n    print(\"Number of unique output tokens:\", num_decoder_tokens)\n    print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n    print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n    \n    input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n    target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n    \n    return input_token_index,target_token_index,max_encoder_seq_length,max_decoder_seq_length,num_encoder_tokens,num_decoder_tokens","metadata":{"execution":{"iopub.status.busy":"2022-05-02T04:58:34.418714Z","iopub.execute_input":"2022-05-02T04:58:34.419409Z","iopub.status.idle":"2022-05-02T04:58:34.431077Z","shell.execute_reply.started":"2022-05-02T04:58:34.41937Z","shell.execute_reply":"2022-05-02T04:58:34.43035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_processing(input_texts,enc_length,input_token_index,num_encoder_tokens, target_texts,dec_length,target_token_index,num_decoder_tokens):\n    encoder_input_data = np.zeros(\n        (len(input_texts), enc_length), dtype=\"float32\"\n    )\n    decoder_input_data = np.zeros(\n            (len(input_texts), dec_length), dtype=\"float32\"\n        )\n    decoder_target_data = np.zeros(\n            (len(input_texts), dec_length, num_decoder_tokens), dtype=\"float32\"\n        )\n\n    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n        \n        for t, char in enumerate(input_text):\n            encoder_input_data[i, t] = input_token_index[char]\n        encoder_input_data[i, t + 1 :] = input_token_index[' ']\n        \n        for t, char in enumerate(target_text):\n                # decoder_target_data is ahead of decoder_input_data by one timestep\n            decoder_input_data[i, t] = target_token_index[char]\n            if t > 0:\n                    # decoder_target_data will be ahead by one timestep\n                    # and will not include the start character.\n                decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n        decoder_input_data[i, t + 1 :] = target_token_index[' ']\n        decoder_target_data[i, t:, target_token_index[' ']] = 1.0\n    return encoder_input_data,decoder_input_data,decoder_target_data","metadata":{"execution":{"iopub.status.busy":"2022-05-02T04:59:03.015097Z","iopub.execute_input":"2022-05-02T04:59:03.016141Z","iopub.status.idle":"2022-05-02T04:59:03.025088Z","shell.execute_reply.started":"2022-05-02T04:59:03.016087Z","shell.execute_reply":"2022-05-02T04:59:03.024408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_token_index,target_token_index,max_encoder_seq_length,max_decoder_seq_length,num_encoder_tokens,num_decoder_tokens = enc_dec_tokens(train_input_texts,train_target_texts,val_input_texts,val_target_texts)\nreverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\nreverse_target_char_index = dict((i, char) for char, i in target_token_index.items())","metadata":{"execution":{"iopub.status.busy":"2022-05-02T04:59:04.835612Z","iopub.execute_input":"2022-05-02T04:59:04.836089Z","iopub.status.idle":"2022-05-02T04:59:04.991876Z","shell.execute_reply.started":"2022-05-02T04:59:04.836052Z","shell.execute_reply":"2022-05-02T04:59:04.991135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_encoder_input,train_decoder_input,train_decoder_target = data_processing(train_input_texts,max_encoder_seq_length,input_token_index,num_encoder_tokens, train_target_texts,max_decoder_seq_length,target_token_index,num_decoder_tokens)\nval_encoder_input,val_decoder_input,val_decoder_target = data_processing(val_input_texts,max_encoder_seq_length,input_token_index,num_encoder_tokens, val_target_texts,max_decoder_seq_length,target_token_index,num_decoder_tokens)\ntest_encoder_input,test_decoder_input,test_decoder_target = data_processing(test_input_texts,max_encoder_seq_length,input_token_index,num_encoder_tokens, test_target_texts,max_decoder_seq_length,target_token_index,num_decoder_tokens)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T04:59:08.968154Z","iopub.execute_input":"2022-05-02T04:59:08.96885Z","iopub.status.idle":"2022-05-02T04:59:10.801551Z","shell.execute_reply.started":"2022-05-02T04:59:08.968813Z","shell.execute_reply":"2022-05-02T04:59:10.800809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_model(num_encoder_tokens,num_decoder_tokens,input_embedding_size=32,num_enc_layers=1,num_dec_layers=1,hidden_layer_size=64,cell_type='LSTM',dropout=0,r_dropout=0,cell_activation='tanh'):\n    cell = {\n        'RNN':SimpleRNN,\n        'LSTM':LSTM,\n        'GRU':GRU\n    }\n    encoder_input = Input(shape=(None,),name='input_1')\n    encoder_input_embedding = Embedding(num_encoder_tokens,input_embedding_size,name='embedding_1')(encoder_input)\n    \n    encoder_sequences, *encoder_state = cell[cell_type](hidden_layer_size,activation=cell_activation,return_sequences=True,return_state=True,dropout=dropout,recurrent_dropout=r_dropout,name=\"encoder_1\")(encoder_input_embedding)\n    \n    for i in range(1,num_enc_layers):\n        encoder_sequences, *encoder_state = cell[cell_type](hidden_layer_size,activation=cell_activation,return_sequences=True,return_state=True,dropout=dropout,recurrent_dropout=r_dropout,name=f\"encoder_{i+1}\")(encoder_sequences)\n        \n    decoder_input = Input(shape=(None,),name='input_2')\n    decoder_input_embedding = Embedding(num_decoder_tokens,input_embedding_size,name='embedding_2')(decoder_input)\n    \n    decoder_sequences, *decoder_state = cell[cell_type](hidden_layer_size,activation=cell_activation,return_sequences=True,return_state=True,dropout=dropout,recurrent_dropout=r_dropout,name=\"decoder_1\")(decoder_input_embedding ,initial_state=encoder_state)\n    \n    for i in range(1,num_dec_layers):\n        decoder_sequences, *decoder_state = cell[cell_type](hidden_layer_size,activation=cell_activation,return_sequences=True,return_state=True,dropout=dropout,recurrent_dropout=r_dropout,name=f\"decoder_{i+1}\")(decoder_sequences ,initial_state=encoder_state)\n    \n    decoder_dense = Dense(num_decoder_tokens,activation=\"softmax\",name=\"dense_1\")(decoder_sequences)\n    \n    model = keras.Model([encoder_input,decoder_input],decoder_dense)\n    model.summary()\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-02T04:59:13.1991Z","iopub.execute_input":"2022-05-02T04:59:13.199357Z","iopub.status.idle":"2022-05-02T04:59:13.211236Z","shell.execute_reply.started":"2022-05-02T04:59:13.199326Z","shell.execute_reply":"2022-05-02T04:59:13.210501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = make_model(num_encoder_tokens,num_decoder_tokens)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T05:23:04.978195Z","iopub.execute_input":"2022-04-28T05:23:04.9788Z","iopub.status.idle":"2022-04-28T05:23:04.992463Z","shell.execute_reply.started":"2022-04-28T05:23:04.978765Z","shell.execute_reply":"2022-04-28T05:23:04.99179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Nadam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.callbacks import EarlyStopping\ndef model_train_util(config):\n    model = make_model(num_encoder_tokens,num_decoder_tokens,config['input_embedding_size'],config['num_enc_layers'],config['num_dec_layers'],config['hidden_layer_size'],config['cell_type'],config['dropout'],config['r_dropout'])\n    optimizer = config['optimizer']\n    if config['loss_function'] == 'categorical_crossentropy':\n        loss_fn = CategoricalCrossentropy\n    if optimizer == 'adam':\n        model.compile(optimizer = Adam(learning_rate=config['learning_rate']), loss = loss_fn(), metrics = ['accuracy'])\n    elif optimizer == 'momentum':\n        model.compile(optimizer = SGD(learning_rate=config['learning_rate'], momentum = 0.9), loss = loss_fn(), metrics = ['accuracy'])\n    elif optimizer == 'rmsprop':\n        model.compile(optimizer = RMSprop(learning_rate=config['learning_rate']), loss = loss_fn(), metrics = ['accuracy'])\n    elif optimizer == 'nesterov':\n        model.compile(optimizer = SGD(learning_rate=config['learning_rate'], momentum = 0.9, nesterov = True), loss = loss_fn(), metrics = ['accuracy'])\n    elif optimizer == 'nadam':\n        model.compile(optimizer = Nadam(learning_rate=config['learning_rate']), loss = loss_fn(), metrics = ['accuracy'])\n    else:\n        model.compile(optimizer = SGD(learning_rate=config['learning_rate']), loss = loss_fn(), metrics = ['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-02T04:59:38.700967Z","iopub.execute_input":"2022-05-02T04:59:38.701245Z","iopub.status.idle":"2022-05-02T04:59:38.712814Z","shell.execute_reply.started":"2022-05-02T04:59:38.701213Z","shell.execute_reply":"2022-05-02T04:59:38.712141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class customCallback(keras.callbacks.Callback):\n     # Custom class to provide callback after each epoch of training to calculate custom metrics for validation set with beam decoder\n    def __init__(self, val_enc_input, val_dec_target, beam_width=1, batch_size=64, attention=False):\n        self.beam_width = beam_width\n        self.validation_input = val_enc_input\n        self.validation_target = val_dec_target\n        self.batch_size = batch_size\n\n    def on_epoch_end(self, epoch, logs):\n        val_accuracy, val_exact_accuracy, val_loss = beam_decoder(self.model, self.validation_input, self.validation_target, max_decoder_seq_length, \n                                                                  target_token_index, reverse_target_char_index, self.beam_width, self.batch_size)\n\n        # Log them to reflect in WANDB callback and EarlyStopping\n        logs[\"val_accuracy\"] = val_accuracy\n        logs[\"val_exact_accuracy\"] = val_exact_accuracy\n        logs[\"val_loss\"] = val_loss             # Validation loss calculates categorical cross entropy loss\n\n        print(\"— val_loss: {:.3f} — val_accuracy: {:.3f} — val_exact_accuracy: {:.5f}\".format(val_loss, val_accuracy, val_exact_accuracy))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:14:24.448035Z","iopub.execute_input":"2022-05-02T07:14:24.448356Z","iopub.status.idle":"2022-05-02T07:14:24.457272Z","shell.execute_reply.started":"2022-05-02T07:14:24.44832Z","shell.execute_reply":"2022-05-02T07:14:24.456182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model,history = model_train_util(config_)\n# model.save(\"s2s\")","metadata":{"execution":{"iopub.status.busy":"2022-04-28T05:23:05.331735Z","iopub.execute_input":"2022-04-28T05:23:05.331995Z","iopub.status.idle":"2022-04-28T05:23:05.344363Z","shell.execute_reply.started":"2022-04-28T05:23:05.33197Z","shell.execute_reply":"2022-04-28T05:23:05.343679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Installing and logging into WANDB\n!pip install --upgrade wandb\n!wandb login b44266d937596fcef83bedbe7330d6cee108a277\n\nimport wandb\nfrom wandb.keras import WandbCallback","metadata":{"execution":{"iopub.status.busy":"2022-05-02T04:59:21.952791Z","iopub.execute_input":"2022-05-02T04:59:21.953542Z","iopub.status.idle":"2022-05-02T04:59:33.534646Z","shell.execute_reply.started":"2022-05-02T04:59:21.9535Z","shell.execute_reply":"2022-05-02T04:59:33.533804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_train(config,iswandb=False):\n    wid = None\n    if iswandb:\n        wid = wandb.util.generate_id()\n        run = wandb.init(id = wid, project=\"cs6910_assignment_3\", entity=\"dlstack\", reinit=True, config=config)\n        wandb.run.name = f\"ies_{config['input_embedding_size']}_nenc_{config['num_enc_layers']}_ndec_{config['num_dec_layers']}_cell_{config['cell_type']}_drop_{config['dropout']}_rdrop_{config['r_dropout']}\"\n        wandb.run.name += f\"_hs_{config['hidden_layer_size']}_B_{config['beam_width']}\"\n        wandb.run.save()\n        print(wandb.run.name)\n\n    model = model_train_util(config)\n    if iswandb:\n        call_list = [customCallback(val_encoder_input,val_decoder_target,beam_width=config['beam_width'],batch_size=config['batch_size']),WandbCallback(monitor='val_accuracy'),EarlyStopping(monitor='val_accuracy',patience=4)]\n    else:\n        call_list = [customCallback(val_encoder_input,val_decoder_target,beam_width=config['beam_width'],batch_size=config['batch_size']),EarlyStopping(monitor='val_accuracy',patience=4)]\n    history = model.fit(\n        [train_encoder_input,train_decoder_input],\n        train_decoder_target,\n        batch_size=config['batch_size'],\n        verbose = 1,\n        epochs=config['epochs'],\n        callbacks = call_list\n    )    \n    if iswandb:\n        run.finish()\n\n    return model, history,config, wid","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:14:35.410222Z","iopub.execute_input":"2022-05-02T07:14:35.410545Z","iopub.status.idle":"2022-05-02T07:14:35.422908Z","shell.execute_reply.started":"2022-05-02T07:14:35.410502Z","shell.execute_reply":"2022-05-02T07:14:35.422105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def wandb_sweep():\n    # Wrapper function to call the model_train() function for sweeping with different hyperparameters\n\n    # Initialize a new wandb run\n    run = wandb.init(config=config_, reinit=True)\n\n    # Config is a variable that holds and saves hyperparameters and inputs\n    config = wandb.config\n\n    wandb.run.name = f'ies_{config.input_embedding_size}_nenc_{config.num_enc_layers}_ndec_{config.num_dec_layers}_cell_{config.cell_type}_drop_{config.dropout}_rdrop_{config.r_dropout}'\n    wandb.run.name += f'_hs_{config.hidden_layer_size}_B_{config.beam_width}'\n    wandb.run.save()\n    print(wandb.run.name)\n\n    model, *_ = model_train(config, iswandb=True)\n    run.finish()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:14:41.484973Z","iopub.execute_input":"2022-05-02T07:14:41.485252Z","iopub.status.idle":"2022-05-02T07:14:41.492192Z","shell.execute_reply.started":"2022-05-02T07:14:41.48522Z","shell.execute_reply":"2022-05-02T07:14:41.4914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_inference_model(model):\n    # Calculating number of layers in encoder and decoder\n    num_enc_layers, num_dec_layers = 0, 0\n    for layer in model.layers:\n        num_enc_layers += layer.name.startswith('encoder')\n        num_dec_layers += layer.name.startswith('decoder')\n\n    # Encoder input\n    encoder_input = model.input[0]      # Input_1\n    # Encoder cell final layer\n    encoder_cell = model.get_layer(\"encoder_\"+str(num_enc_layers))\n    encoder_type = encoder_cell.__class__.__name__\n    encoder_seq, *encoder_state = encoder_cell.output\n    # Encoder model\n    encoder_model = keras.Model(encoder_input, encoder_state)\n\n    # Decoder input\n    decoder_input = model.input[1]      # Input_2\n    decoder_input_embedding = model.get_layer(\"embedding_2\")(decoder_input)\n    decoder_sequences = decoder_input_embedding\n    # Inputs to decoder layers' initial states\n    decoder_states, decoder_state_inputs = [], []\n    for i in range(1, num_dec_layers+1):\n        if encoder_type == 'LSTM':\n            decoder_state_input = [Input(shape=(encoder_state[0].shape[1],), name=\"input_\"+str(2*i+1)), \n                                   Input(shape=(encoder_state[1].shape[1],), name=\"input_\"+str(2*i+2))]\n        else:\n            decoder_state_input = [Input(shape=(encoder_state[0].shape[1],), name=\"input_\"+str(i+2))]\n\n        decoder_cell = model.get_layer(\"decoder_\"+str(i))\n        decoder_sequences, *decoder_state = decoder_cell(decoder_sequences, initial_state=decoder_state_input)\n        decoder_states += decoder_state\n        decoder_state_inputs += decoder_state_input\n\n    # Softmax FC layer\n    decoder_dense = model.get_layer(\"dense_1\")\n    decoder_dense_output = decoder_dense(decoder_sequences)\n\n    # Decoder model\n    decoder_model = keras.Model(\n        [decoder_input] + decoder_state_inputs, [decoder_dense_output] + decoder_states\n    )\n\n    return encoder_model, decoder_model, num_enc_layers, num_dec_layers\n\n\ndef num_to_word(num_encoded, token_index, reverse_char_index = None):\n    # Function to return the predictions after cutting the END_CHAR and BLANK_CHAR s at the end.\n    # If char_dec == None, the predictions are in the form of decoded string, otherwise as list of integers\n    num_samples = len(num_encoded) if type(num_encoded) is list else num_encoded.shape[0]\n    predicted_words = ['' for t in range(num_samples)]\n    for i, encode in enumerate(num_encoded):\n        for l in encode:\n            # Stop word : '\\n'\n            if l == token_index['\\n']:\n                break\n            predicted_words[i] += reverse_char_index[l] if reverse_char_index is not None else str(l)\n    \n    return predicted_words","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-02T07:14:43.81182Z","iopub.execute_input":"2022-05-02T07:14:43.812319Z","iopub.status.idle":"2022-05-02T07:14:43.827714Z","shell.execute_reply.started":"2022-05-02T07:14:43.812281Z","shell.execute_reply":"2022-05-02T07:14:43.826741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def beam_decoder_util(model,input_sequences,max_decoder_seq_length,B=1,target_sequences=None,start_char=0,batch_size=64):\n    encoder_model,decoder_model,num_enc_layers,num_dec_layers=make_inference_model(model)\n    encoder_output = encoder_model.predict(input_sequences,batch_size=batch_size)\n    encoder_output = encoder_output if type(encoder_output) is list else [encoder_output]\n    \n    num_samples = input_sequences.shape[0]\n    \n    outputs_fn = np.zeros((num_samples,B,max_decoder_seq_length),dtype=np.int32)\n    \n    errors_fn = np.zeros((num_samples,B))\n    \n    decoder_b_inputs = np.zeros((num_samples,1,1))\n    decoder_b_inputs[:, :, 0] = start_char\n    \n    decoder_b_out = [[(0, [])] for t in range(num_samples)]\n    errors = [[0] for t in range(num_samples)]\n    \n    states = [encoder_output*num_dec_layers]\n    \n    for idx in range(max_decoder_seq_length):\n        all_b_beams = [[] for t in range(num_samples)]\n        all_decoder_states = [[] for t in range(num_samples)]\n        all_errors = [[] for t in range(num_samples)]\n        for b in range(len(decoder_b_out[0])):\n            decoder_output, *decoder_states = decoder_model.predict([decoder_b_inputs[:,b]] + states[b],batch_size=batch_size)\n            top_b = np.argsort(decoder_output[:,-1,:],axis=-1)[:,-B:]\n            for n in range(num_samples):\n                all_b_beams[n]+= [(decoder_b_out[n][b][0] + np.log(decoder_output[n, -1, top_b[n][i]]),decoder_b_out[n][b][1] + [top_b[n][i]]) for i in range(B)]\n                if target_sequences is not None:\n                    all_errors[n] += [errors[n][b] - np.log(decoder_output[n,-1,target_sequences[n,idx]])]*B\n                all_decoder_states[n] += [[decoder_state[n:n+1] for decoder_state in decoder_states]] * B\n        sorted_index = list(range(len(all_b_beams[0])))\n        sorted_index = [sorted(sorted_index,key = lambda ix: all_b_beams[n][ix][0])[-B:][::-1] for n in range(num_samples)]\n        decoder_b_out = [[all_b_beams[n][index] for index in sorted_index[n]] for n in range(num_samples)]\n        \n        decoder_b_inputs = np.array([[all_b_beams[n][index][1][-1] for index in sorted_index[n]] for n in range(num_samples)])\n        \n        states = [all_decoder_states[0][index] for index in sorted_index[0]]\n        \n        for n in range(1,num_samples):\n            states = [[np.concatenate((states[i][j],all_decoder_states[n][index][j])) for j in range(len(all_decoder_states[n][index]))] for i,index in  enumerate(sorted_index[n])]\n        if target_sequences is not None:\n            errors = [[all_errors[n][index] for index in sorted_index[n]] for n in range(num_samples)]\n    outputs_fn = np.array([[decoder_b_out[n][i][1] for i in range(B)] for n in range(num_samples)])\n    if target_sequences is not None:\n        errors_fn = np.array(errors)/max_decoder_seq_length\n    return outputs_fn,errors_fn,np.array(states)\ndef calc_metrics(b_outputs, target_sequences,token_index,reverse_char_index,b_errors=None,exact_word=True,display=False):\n    matches = np.mean(b_outputs == target_sequences.reshape(target_sequences.shape[0],1,target_sequences.shape[1]),axis=-1)\n    best_b = np.argmax(matches,axis=-1)\n    best_index = (tuple(range(best_b.shape[0])),tuple(best_b))\n    accuracy = np.mean(matches[best_index])\n    b_predictions = list()\n    loss = None\n    if b_errors is not None:\n        loss = np.mean(b_errors[best_index])\n    if exact_word:\n        equal = [0] * b_outputs.shape[0]\n        true_out = num_to_word(target_sequences,token_index,reverse_char_index)\n        for b in range(b_outputs.shape[1]):\n            pred_out = num_to_word(b_outputs[:,b], token_index,reverse_char_index)\n            equal = [equal[i] or (pred_out[i] == true_out[i]) for i in range(b_outputs.shape[0])]\n            if display==True:\n                b_predictions.append(pred_out)\n        exact_accuracy = np.mean(equal)\n        if display==True:\n            return accuracy,exact_accuracy,loss,true_out,b_predictions\n        return accuracy,exact_accuracy,loss\n    return accuracy,loss\ndef beam_decoder(model,input_sequences,target_sequences_onehot,max_decoder_seq_length,token_index,reverse_char_index,B=1,model_batch_size=64,infer_batch_size=512,exact_word=True,return_outputs=False,return_states=False,display=False):\n    target_sequences = np.argmax(target_sequences_onehot,axis=-1)\n    b_outputs,b_errors,b_states=None,None,None\n    for i in range(0,input_sequences.shape[0],infer_batch_size):\n        tmp_b_outputs,tmp_b_errors,tmp_b_states = beam_decoder_util(model,input_sequences[i:i+infer_batch_size],max_decoder_seq_length,B,target_sequences[i:i+infer_batch_size],token_index['\\t'],model_batch_size)\n        \n        if b_errors is None:\n            b_outputs,b_errors,b_states = tmp_b_outputs,tmp_b_errors,tmp_b_states\n        else:\n            b_outputs = np.concatenate((b_outputs,tmp_b_outputs))\n            b_errors = np.concatenate((b_errors,tmp_b_errors))\n            b_states = np.concatenate((b_states,tmp_b_states),axis=2)\n    return_elements = []\n    if return_outputs:\n        return_elements += [b_outputs]\n    if return_states:\n        return_elements += [b_states]\n    if len(return_elements) > 0:\n        return calc_metrics(b_outputs,target_sequences,token_index,reverse_char_index,b_errors,exact_word,display) + tuple(return_elements)\n    return calc_metrics(b_outputs,target_sequences,target_token_index,reverse_char_index,b_errors,exact_word,display)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:28:39.786009Z","iopub.execute_input":"2022-05-02T05:28:39.786504Z","iopub.status.idle":"2022-05-02T05:28:39.820361Z","shell.execute_reply.started":"2022-05-02T05:28:39.786443Z","shell.execute_reply":"2022-05-02T05:28:39.819586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model, history,config, wid = model_train(config=config_,iswandb=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:00:05.009801Z","iopub.execute_input":"2022-05-02T05:00:05.010063Z","iopub.status.idle":"2022-05-02T05:00:05.015222Z","shell.execute_reply.started":"2022-05-02T05:00:05.010032Z","shell.execute_reply":"2022-05-02T05:00:05.014388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameter choices to sweep \nsweep_config_1 = {\n    'name': 'RNNs2s',\n    'method': 'bayes',                   # Possible search : grid, random, bayes\n    'metric': {\n      'name': 'val_accuracy',\n      'goal': 'maximize'   \n    },\n    'parameters': {\n        'epochs':{\n            'values':[10]\n        },\n        'learning_rate':{\n            'values':[0.001]\n        },\n        'optimizer':{\n            'value':'adam'\n        },\n        'loss_function':{\n          'value':'categorical_crossentropy'  \n        },\n        'input_embedding_size': {\n            'values': [256]\n        },\n        'num_enc_layers': {\n            'values': [2]\n        },\n        'num_dec_layers': {\n            'values': [3]\n        },\n        'hidden_layer_size': {\n            'values': [256]\n        },\n        'cell_type': {\n            'values': ['GRU']\n        },\n        'dropout' :{\n            'values': [0.30]\n        },\n        'r_dropout': {\n            'values': [0.30]\n        },\n        'beam_width': {\n            'values': [3]\n        },\n        'batch_size':{\n            'values':[256]\n        }\n    }\n}\nsweep_id = wandb.sweep(sweep_config_1,entity='dlstack',project='cs6910_assignment_3')\nwandb.agent(sweep_id,lambda:wandb_sweep(),count=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:29:05.739445Z","iopub.execute_input":"2022-05-02T05:29:05.739922Z","iopub.status.idle":"2022-05-02T06:28:04.606807Z","shell.execute_reply.started":"2022-05-02T05:29:05.739886Z","shell.execute_reply":"2022-05-02T06:28:04.606111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameter choices to sweep \nsweep_config_1 = {\n    'name': 'RNNs2s',\n    'method': 'bayes',                   # Possible search : grid, random, bayes\n    'metric': {\n      'name': 'val_accuracy',\n      'goal': 'maximize'   \n    },\n    'parameters': {\n        'epochs':{\n            'values':[10,15,20,30,40]\n        },\n        'learning_rate':{\n            'values':[1e-3,1e-4]\n        },\n        'optimizer':{\n            'value':'adam'\n        },\n        'loss_function':{\n          'value':'categorical_crossentropy'  \n        },\n        'input_embedding_size': {\n            'values': [32, 64, 128,256]\n        },\n        'num_enc_layers': {\n            'values': [2,3]\n        },\n        'num_dec_layers': {\n            'values': [2,3,5]\n        },\n        'hidden_layer_size': {\n            'values': [ 128,256,512,768]\n        },\n        'cell_type': {\n            'values': [ 'RNN','LSTM', 'GRU']\n        },\n        'dropout' :{\n            'values': [0.20,0.25,0.30]\n        },\n        'r_dropout':{\n          'values': [0.0,0.20,0.30]  \n        },\n        'beam_width': {\n            'values': [1, 3,5]\n        },\n        'batch_size':{\n            'values':[64,128,256]\n        }\n    }\n}\nsweep_id = wandb.sweep(sweep_config_1,entity='dlstack',project='cs6910_assignment_3')\nwandb.agent(sweep_id,lambda:wandb_sweep(),count=20)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T09:05:55.379012Z","iopub.execute_input":"2022-05-02T09:05:55.379348Z","iopub.status.idle":"2022-05-02T09:05:55.463891Z","shell.execute_reply.started":"2022-05-02T09:05:55.379268Z","shell.execute_reply":"2022-05-02T09:05:55.462288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameter choices to sweep \nsweep_config_1 = {\n    'name': 'RNNs2s',\n    'method': 'bayes',                   # Possible search : grid, random, bayes\n    'metric': {\n      'name': 'val_accuracy',\n      'goal': 'maximize'   \n    },\n    'parameters': {\n        'epochs':{\n            'values':[10,20,30]\n        },\n        'learning_rate':{\n            'values':[1e-3,1e-4]\n        },\n        'optimizer':{\n            'values':['rmsprop','adam','nadam','nesterov','sgd']\n        },\n        'loss_function':{\n          'value':'categorical_crossentropy'  \n        },\n        'input_embedding_size': {\n            'values': [32, 64,256]\n        },\n        'num_enc_layers': {\n            'values': [ 2, 3,4]\n        },\n        'num_dec_layers': {\n            'values': [ 2, 3,4]\n        },\n        'hidden_layer_size': {\n            'values': [64, 128, 256,512]\n        },\n        'cell_type': {\n            'values': ['RNN', 'LSTM', 'GRU']\n        },\n        'dropout' :{\n            'values': [0, 0.25, 0.3,0.4]\n        },\n        'r_dropout':{\n          'values':[0.0,0.1]  \n        },\n        'batch_size':{\n          'values':[64,128,256]  \n        },\n        'beam_width': {\n            'values': [1, 5]\n        }\n    }\n}\nsweep_id = wandb.sweep(sweep_config_1,entity='dlstack',project='cs6910_assignment_3')\nwandb.agent(sweep_id,lambda:wandb_sweep(),count=10)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T01:54:34.098732Z","iopub.status.idle":"2022-05-02T01:54:34.099385Z","shell.execute_reply.started":"2022-05-02T01:54:34.099142Z","shell.execute_reply":"2022-05-02T01:54:34.099168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def levenshtein(s1, s2):\n    # Function to calculate levenshtein distance between two sequences usign Dynamic Programming\n    m, n = len(s1)+1, len(s2)+1\n    # Initialisation\n    dp = np.zeros((m, n))\n    # Base case\n    dp[0,1:] = np.arange(1,n)\n    dp[1:,0] = np.arange(1,m)\n\n    # Recursion\n    for i in range(1,m):\n        for j in range(1,n):\n            if s1[i-1] == s2[j-1]:\n                dp[i,j] = min(dp[i-1,j-1], dp[i-1,j]+1, dp[i,j-1]+1)\n            else:\n                dp[i,j] = min(dp[i,j-1], dp[i-1,j], dp[i-1,j-1]) + 1\n    \n    return dp[m-1,n-1]","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:07:41.201329Z","iopub.execute_input":"2022-05-02T07:07:41.202383Z","iopub.status.idle":"2022-05-02T07:07:41.213135Z","shell.execute_reply.started":"2022-05-02T07:07:41.202317Z","shell.execute_reply":"2022-05-02T07:07:41.212444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\nfrom keras.utils.vis_utils import plot_model\ndef test_model(run_id,test_encoder_input,test_decoder_target,max_decoder_seq_length,target_token_index,reverse_target_char_index,save_pred=False,test_input_texts=None):\n    api = wandb.Api()\n    r = api.run('dlstack/cs6910_assignment_3/'+run_id)\n#     print(r.config)\n    config = r.config['_items'] if '_items' in r.config.keys() else r.config\n#     print(config)\n    model_file = r.file('model-best.h5').download(replace=True)\n    model = keras.models.load_model(model_file.name)\n    num_samples,batch_size,B = test_encoder_input.shape[0],config['batch_size'],config['beam_width']\n    acc, exact_B_acc, loss, outputs = beam_decoder(model, test_encoder_input, test_decoder_target, max_decoder_seq_length, \n                                                                target_token_index, reverse_target_char_index,B, batch_size,\n                                                                return_outputs=True)\n    print(f'Test accuracy (using exact word match with beam width = {B}) : {exact_B_acc*100:.2f}%')\n    \n    test_target = np.argmax(test_decoder_target, axis=-1)\n    true_out = num_to_word(test_target, target_token_index, reverse_target_char_index)\n    pred_out = [[] for t in range(num_samples)]\n    pred_scores = [[] for t in range(num_samples)]\n    for b in range(B):\n        pred = num_to_word(outputs[:,b], target_token_index, reverse_target_char_index)\n        pred_out = [pred_out[n] + [pred[n]] for n in range(num_samples)]\n        pred_scores = [pred_scores[n] + [levenshtein(pred[n], true_out[n])] for n in range(num_samples)]\n\n    equal = [pred_out[n][0] == true_out[n] for n in range(num_samples)]\n    exact_acc = np.mean(equal)\n\n    print(f'Test accuracy (using exact word match of the first prediction) : {exact_acc*100:.2f}%')\n    print('\\n')\n    save_pred = True\n    if save_pred:\n        # We write the input and top K outputs in decreasing order of probabilities to the file\n        pred_file_name = 'predictions.csv' \n        with open(pred_file_name, 'w', newline='') as file:\n            writer = csv.writer(file)\n            writer.writerow([\"Input\"] + [\"Prediction_\"+str(b+1) for b in range(B)])\n            for n in range(num_samples):\n                writer.writerow([test_input_texts[n]] + [pred_out[n][b] for b in range(B)])\n    return acc, exact_B_acc, exact_acc, loss, true_out, pred_out, pred_scores, model","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:02:12.526339Z","iopub.execute_input":"2022-05-02T07:02:12.526808Z","iopub.status.idle":"2022-05-02T07:02:12.542185Z","shell.execute_reply.started":"2022-05-02T07:02:12.526762Z","shell.execute_reply":"2022-05-02T07:02:12.541371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc, exact_B_acc, exact_acc, loss, true_out, pred_out, pred_scores, model = test_model('nrd2ctiz',test_encoder_input,test_decoder_target,max_decoder_seq_length,target_token_index,reverse_target_char_index,save_pred=True,test_input_texts=test_input_texts)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:07:43.820982Z","iopub.execute_input":"2022-05-02T07:07:43.821239Z","iopub.status.idle":"2022-05-02T07:10:59.12852Z","shell.execute_reply.started":"2022-05-02T07:07:43.821209Z","shell.execute_reply":"2022-05-02T07:10:59.127745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib\ndef get_clr(value, cmap=None):\n    # Function to get appropriate color for a value between 0 and 1 from the default blue to red hard-coded colors or a matplotlib cmap \n    colors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8',\n        '#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n        '#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n        '#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n    if cmap is not None:\n        rgba = matplotlib.cm.get_cmap(cmap)(value,alpha=None,bytes=True)\n        return 'rgb'+str(rgba[:-1])\n    value = min(int((value * 100) / 5), 19)\n    return colors[value]","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:11:28.573421Z","iopub.execute_input":"2022-05-02T07:11:28.574192Z","iopub.status.idle":"2022-05-02T07:11:28.580769Z","shell.execute_reply.started":"2022-05-02T07:11:28.574153Z","shell.execute_reply":"2022-05-02T07:11:28.579826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import HTML as html_print\nfrom IPython.display import display\nimport random\ndef print_samples(inputs, true_output, pred_output, pred_scores, random_seq=None,cmap=None):\n    '''\n    Function to print sample outputs in a neat format\n    Arguments :\n        inputs -- input words\n        true_output -- true output as words\n        pred_output -- K predicted output words\n        pred_scores -- levenshtein distance for the predictions to the true output\n        random_seq -- list of indices from the dataset passed for which the sample outputs are to be printed (If None, random 10 samples will be chosen)\n    Returns :\n        random_seq -- the list of indices for which sample outputs are printed\n    '''\n    num_samples = len(true_output)\n    if random_seq is None:\n        random_seq = random.sample(range(num_samples),10)\n    print('-'*20 + f' Top {len(pred_scores[0])} predictions in decreasing order of probabilities for 10 random samples ' + '-'*20)\n    print('')\n    for i in random_seq:\n        K = len(pred_scores[i])\n        html_str = '''\n        <table style=\"border:2px solid black; border-collapse:collapse\">\n        <caption> <strong>INPUT :</strong> {} &emsp; | &emsp; <strong> TRUE OUTPUT : </strong> {} </caption>\n        <tr>\n        <th scope=\"row\" style=\"border:1px solid black;padding:10px;text-align:left\"> Top {} Predictions </th>\n        '''.format(inputs[i], true_output[i], K)\n        for k in range(K):\n            html_str += '''\n            <td style=\"color:#000;background-color:{};border:1px solid black;padding:10px\"> {} </td>\n            '''.format(get_clr(pred_scores[i][k]/5,cmap), pred_out[i][k])\n        html_str += '''\n        </tr>\n        <tr>\n        <th scope=\"row\" style=\"border:1px solid black;padding:10px;text-align:left\"> Levenshtein distance (to true output) &emsp; </th>\n        '''\n        for k in range(K):\n            html_str += '''\n            <td style=\"border:1px solid black;padding:10px\"> {} </td>\n            '''.format(pred_scores[i][k])\n        html_str += '''\n        </tr>\n        </table>\n        '''\n        display(html_print(html_str))\n        print('\\n\\n')\n    \n    return random_seq","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:11:51.13876Z","iopub.execute_input":"2022-05-02T07:11:51.139065Z","iopub.status.idle":"2022-05-02T07:11:51.149919Z","shell.execute_reply.started":"2022-05-02T07:11:51.139027Z","shell.execute_reply":"2022-05-02T07:11:51.149137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_samples = print_samples(test_input_texts,true_out,pred_out,pred_scores)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:12:11.796352Z","iopub.execute_input":"2022-05-02T07:12:11.796863Z","iopub.status.idle":"2022-05-02T07:12:11.827668Z","shell.execute_reply.started":"2022-05-02T07:12:11.796817Z","shell.execute_reply":"2022-05-02T07:12:11.82698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model,show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:12:42.260308Z","iopub.execute_input":"2022-05-02T07:12:42.260596Z","iopub.status.idle":"2022-05-02T07:12:43.125067Z","shell.execute_reply.started":"2022-05-02T07:12:42.260564Z","shell.execute_reply":"2022-05-02T07:12:43.124198Z"},"trusted":true},"execution_count":null,"outputs":[]}]}