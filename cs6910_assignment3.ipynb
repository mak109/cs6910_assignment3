{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wget","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:04:55.017342Z","iopub.execute_input":"2022-05-03T03:04:55.017887Z","iopub.status.idle":"2022-05-03T03:05:07.055944Z","shell.execute_reply.started":"2022-05-03T03:04:55.017844Z","shell.execute_reply":"2022-05-03T03:05:07.054908Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import wget\nimport os\nimport tarfile","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:07.058488Z","iopub.execute_input":"2022-05-03T03:05:07.058759Z","iopub.status.idle":"2022-05-03T03:05:07.071515Z","shell.execute_reply.started":"2022-05-03T03:05:07.058723Z","shell.execute_reply":"2022-05-03T03:05:07.070790Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:07.074141Z","iopub.execute_input":"2022-05-03T03:05:07.074688Z","iopub.status.idle":"2022-05-03T03:05:07.078165Z","shell.execute_reply.started":"2022-05-03T03:05:07.074653Z","shell.execute_reply":"2022-05-03T03:05:07.077393Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:07.080499Z","iopub.execute_input":"2022-05-03T03:05:07.080903Z","iopub.status.idle":"2022-05-03T03:05:11.167520Z","shell.execute_reply.started":"2022-05-03T03:05:07.080853Z","shell.execute_reply":"2022-05-03T03:05:11.166793Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from keras.layers import SimpleRNN,GRU,LSTM,Embedding,Input,Dense","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:11.168950Z","iopub.execute_input":"2022-05-03T03:05:11.169208Z","iopub.status.idle":"2022-05-03T03:05:11.845924Z","shell.execute_reply.started":"2022-05-03T03:05:11.169174Z","shell.execute_reply":"2022-05-03T03:05:11.845205Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"filename = 'dakshina_dataset_v1.0'\nurl = 'https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar'\nif not os.path.exists(filename+'.tar') and not os.path.exists(filename):\n    filename_tar = wget.download(url)\n    file = tarfile.open(filename_tar)\n    print('\\nExtracting files ....')\n    file.extractall()\n    file.close()\n    print('Done')\n    os.remove(filename_tar)\nelif not os.path.exists(filename):\n    filename_tar = filename + '.tar'\n    file = tarfile.open(filename_tar)\n    print('\\nExtracting files ....')\n    file.extractall()\n    file.close()\n    print('Done')\n    os.remove(filename_tar)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:11.847343Z","iopub.execute_input":"2022-05-03T03:05:11.847599Z","iopub.status.idle":"2022-05-03T03:05:37.142014Z","shell.execute_reply.started":"2022-05-03T03:05:11.847565Z","shell.execute_reply":"2022-05-03T03:05:37.141254Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"lang = 'bn'\ntrain_path =  filename+f\"/{lang}/lexicons/{lang}.translit.sampled.train.tsv\"\nval_path = filename+f\"/{lang}/lexicons/{lang}.translit.sampled.dev.tsv\"\ntest_path = filename+f\"/{lang}/lexicons/{lang}.translit.sampled.test.tsv\"","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:37.143646Z","iopub.execute_input":"2022-05-03T03:05:37.143897Z","iopub.status.idle":"2022-05-03T03:05:37.150091Z","shell.execute_reply.started":"2022-05-03T03:05:37.143864Z","shell.execute_reply":"2022-05-03T03:05:37.148248Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def read_data(path):\n    df = pd.read_csv(path,header=None,sep='\\t')\n    df.fillna(\"NaN\",inplace=True)\n    input_texts,target_texts = df[1].to_list(),df[0].to_list()\n    return input_texts,target_texts","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:37.151162Z","iopub.execute_input":"2022-05-03T03:05:37.151412Z","iopub.status.idle":"2022-05-03T03:05:38.201869Z","shell.execute_reply.started":"2022-05-03T03:05:37.151381Z","shell.execute_reply":"2022-05-03T03:05:38.200980Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def parse_text(texts):\n    characters = set()\n    for text in texts:\n        for c in text:\n            if c not in characters:\n                characters.add(c)\n    characters.add(' ')\n    return sorted(list(characters))","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:38.203646Z","iopub.execute_input":"2022-05-03T03:05:38.204273Z","iopub.status.idle":"2022-05-03T03:05:39.360074Z","shell.execute_reply.started":"2022-05-03T03:05:38.204232Z","shell.execute_reply":"2022-05-03T03:05:39.355036Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def start_end_pad(texts):\n    for i in range(len(texts)):\n        texts[i] = \"\\t\" + texts[i] + \"\\n\"\n    return texts","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:39.363811Z","iopub.execute_input":"2022-05-03T03:05:39.364045Z","iopub.status.idle":"2022-05-03T03:05:40.615370Z","shell.execute_reply.started":"2022-05-03T03:05:39.364017Z","shell.execute_reply":"2022-05-03T03:05:40.614575Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_input_texts,train_target_texts = read_data(train_path)\nval_input_texts,val_target_texts = read_data(val_path)\ntest_input_texts,test_target_texts = read_data(test_path)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:40.616488Z","iopub.execute_input":"2022-05-03T03:05:40.616762Z","iopub.status.idle":"2022-05-03T03:05:42.488566Z","shell.execute_reply.started":"2022-05-03T03:05:40.616726Z","shell.execute_reply":"2022-05-03T03:05:42.487842Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_target_texts = start_end_pad(train_target_texts)\nval_target_texts = start_end_pad(val_target_texts)\ntest_target_texts = start_end_pad(test_target_texts)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:42.490844Z","iopub.execute_input":"2022-05-03T03:05:42.491257Z","iopub.status.idle":"2022-05-03T03:05:43.890947Z","shell.execute_reply.started":"2022-05-03T03:05:42.491220Z","shell.execute_reply":"2022-05-03T03:05:43.890112Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"config_ = {\n    \"learning_rate\": 1e-3,                                      # Learning rate in gradient descent\n    \"epochs\": 20,                                               # Number of epochs to train the model   \n    \"optimizer\": 'adam',                                        # Gradient descent algorithm used for the parameter updation\n    \"batch_size\": 64,                                           # Batch size used for the optimizer\n    \"loss_function\": 'categorical_crossentropy',                # Loss function used in the optimizer                                                                      # Name of dataset\n    \"input_embedding_size\": 256,                                        # Size of input embedding layer\n    \"num_enc_layers\": 2,                                         # Number of layers in the encoder\n    \"num_dec_layers\": 5,                                         # Number of layers in the decoder\n    \"hidden_layer_size\": 768,                                      # Size of hidden layer\n    \"dropout\" : 0.30,\n    'r_dropout':0.30,# Value of dropout used in the normal and recurrent dropout\n    \"cell_type\": 'GRU',                                         # Type of cell used in the encoder and decoder ('RNN' or 'GRU' or 'LSTM')\n    \"beam_width\": 1                                          # Beam width used in beam decoder                                        \n}","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:43.893181Z","iopub.execute_input":"2022-05-03T03:05:43.893676Z","iopub.status.idle":"2022-05-03T03:05:43.904123Z","shell.execute_reply.started":"2022-05-03T03:05:43.893640Z","shell.execute_reply":"2022-05-03T03:05:43.903264Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def enc_dec_tokens(train_input_texts,train_target_texts,val_input_texts,val_target_texts):\n    \n    input_characters = parse_text(train_input_texts + val_input_texts)\n    target_characters = parse_text(train_target_texts + val_target_texts)\n    num_encoder_tokens = len(input_characters)\n    num_decoder_tokens = len(target_characters)\n    max_encoder_seq_length = max([len(txt) for txt in train_input_texts + val_input_texts])\n    max_decoder_seq_length = max([len(txt) for txt in train_target_texts + val_target_texts])\n\n    print(\"Number of training samples:\", len(train_input_texts))\n    print(\"Number of validation samples:\", len(val_input_texts))\n    print(\"Number of unique input tokens:\", num_encoder_tokens)\n    print(\"Number of unique output tokens:\", num_decoder_tokens)\n    print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n    print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n    \n    input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n    target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n    \n    return input_token_index,target_token_index,max_encoder_seq_length,max_decoder_seq_length,num_encoder_tokens,num_decoder_tokens","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:43.905537Z","iopub.execute_input":"2022-05-03T03:05:43.905861Z","iopub.status.idle":"2022-05-03T03:05:43.916745Z","shell.execute_reply.started":"2022-05-03T03:05:43.905809Z","shell.execute_reply":"2022-05-03T03:05:43.916041Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def data_processing(input_texts,enc_length,input_token_index,num_encoder_tokens, target_texts,dec_length,target_token_index,num_decoder_tokens):\n    encoder_input_data = np.zeros(\n        (len(input_texts), enc_length), dtype=\"float32\"\n    )\n    decoder_input_data = np.zeros(\n            (len(input_texts), dec_length), dtype=\"float32\"\n        )\n    decoder_target_data = np.zeros(\n            (len(input_texts), dec_length, num_decoder_tokens), dtype=\"float32\"\n        )\n\n    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n        \n        for t, char in enumerate(input_text):\n            encoder_input_data[i, t] = input_token_index[char]\n        encoder_input_data[i, t + 1 :] = input_token_index[' ']\n        \n        for t, char in enumerate(target_text):\n                # decoder_target_data is ahead of decoder_input_data by one timestep\n            decoder_input_data[i, t] = target_token_index[char]\n            if t > 0:\n                    # decoder_target_data will be ahead by one timestep\n                    # and will not include the start character.\n                decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n        decoder_input_data[i, t + 1 :] = target_token_index[' ']\n        decoder_target_data[i, t:, target_token_index[' ']] = 1.0\n    return encoder_input_data,decoder_input_data,decoder_target_data","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:43.918990Z","iopub.execute_input":"2022-05-03T03:05:43.919524Z","iopub.status.idle":"2022-05-03T03:05:43.929432Z","shell.execute_reply.started":"2022-05-03T03:05:43.919485Z","shell.execute_reply":"2022-05-03T03:05:43.928679Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"input_token_index,target_token_index,max_encoder_seq_length,max_decoder_seq_length,num_encoder_tokens,num_decoder_tokens = enc_dec_tokens(train_input_texts,train_target_texts,val_input_texts,val_target_texts)\nreverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\nreverse_target_char_index = dict((i, char) for char, i in target_token_index.items())","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:43.930866Z","iopub.execute_input":"2022-05-03T03:05:43.931149Z","iopub.status.idle":"2022-05-03T03:05:44.086424Z","shell.execute_reply.started":"2022-05-03T03:05:43.931116Z","shell.execute_reply":"2022-05-03T03:05:44.085715Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_encoder_input,train_decoder_input,train_decoder_target = data_processing(train_input_texts,max_encoder_seq_length,input_token_index,num_encoder_tokens, train_target_texts,max_decoder_seq_length,target_token_index,num_decoder_tokens)\nval_encoder_input,val_decoder_input,val_decoder_target = data_processing(val_input_texts,max_encoder_seq_length,input_token_index,num_encoder_tokens, val_target_texts,max_decoder_seq_length,target_token_index,num_decoder_tokens)\ntest_encoder_input,test_decoder_input,test_decoder_target = data_processing(test_input_texts,max_encoder_seq_length,input_token_index,num_encoder_tokens, test_target_texts,max_decoder_seq_length,target_token_index,num_decoder_tokens)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:44.087511Z","iopub.execute_input":"2022-05-03T03:05:44.087743Z","iopub.status.idle":"2022-05-03T03:05:45.884425Z","shell.execute_reply.started":"2022-05-03T03:05:44.087707Z","shell.execute_reply":"2022-05-03T03:05:45.883550Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def make_model(num_encoder_tokens,num_decoder_tokens,input_embedding_size=32,num_enc_layers=1,num_dec_layers=1,hidden_layer_size=64,cell_type='LSTM',dropout=0,r_dropout=0,cell_activation='tanh'):\n    cell = {\n        'RNN':SimpleRNN,\n        'LSTM':LSTM,\n        'GRU':GRU\n    }\n    encoder_input = Input(shape=(None,),name='input_1')\n    encoder_input_embedding = Embedding(num_encoder_tokens,input_embedding_size,name='embedding_1')(encoder_input)\n    \n    encoder_sequences, *encoder_state = cell[cell_type](hidden_layer_size,activation=cell_activation,return_sequences=True,return_state=True,dropout=dropout,recurrent_dropout=r_dropout,name=\"encoder_1\")(encoder_input_embedding)\n    \n    for i in range(1,num_enc_layers):\n        encoder_sequences, *encoder_state = cell[cell_type](hidden_layer_size,activation=cell_activation,return_sequences=True,return_state=True,dropout=dropout,recurrent_dropout=r_dropout,name=f\"encoder_{i+1}\")(encoder_sequences)\n        \n    decoder_input = Input(shape=(None,),name='input_2')\n    decoder_input_embedding = Embedding(num_decoder_tokens,input_embedding_size,name='embedding_2')(decoder_input)\n    \n    decoder_sequences, *decoder_state = cell[cell_type](hidden_layer_size,activation=cell_activation,return_sequences=True,return_state=True,dropout=dropout,recurrent_dropout=r_dropout,name=\"decoder_1\")(decoder_input_embedding ,initial_state=encoder_state)\n    \n    for i in range(1,num_dec_layers):\n        decoder_sequences, *decoder_state = cell[cell_type](hidden_layer_size,activation=cell_activation,return_sequences=True,return_state=True,dropout=dropout,recurrent_dropout=r_dropout,name=f\"decoder_{i+1}\")(decoder_sequences ,initial_state=encoder_state)\n    \n    decoder_dense = Dense(num_decoder_tokens,activation=\"softmax\",name=\"dense_1\")(decoder_sequences)\n    \n    model = keras.Model([encoder_input,decoder_input],decoder_dense)\n    model.summary()\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:45.885896Z","iopub.execute_input":"2022-05-03T03:05:45.886175Z","iopub.status.idle":"2022-05-03T03:05:45.899322Z","shell.execute_reply.started":"2022-05-03T03:05:45.886134Z","shell.execute_reply":"2022-05-03T03:05:45.898647Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# model = make_model(num_encoder_tokens,num_decoder_tokens)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:45.900899Z","iopub.execute_input":"2022-05-03T03:05:45.901219Z","iopub.status.idle":"2022-05-03T03:05:45.909557Z","shell.execute_reply.started":"2022-05-03T03:05:45.901184Z","shell.execute_reply":"2022-05-03T03:05:45.908855Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Nadam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.callbacks import EarlyStopping\ndef model_train_util(config):\n    model = make_model(num_encoder_tokens,num_decoder_tokens,config['input_embedding_size'],config['num_enc_layers'],config['num_dec_layers'],config['hidden_layer_size'],config['cell_type'],config['dropout'],config['r_dropout'])\n    optimizer = config['optimizer']\n    if config['loss_function'] == 'categorical_crossentropy':\n        loss_fn = CategoricalCrossentropy\n    if optimizer == 'adam':\n        model.compile(optimizer = Adam(learning_rate=config['learning_rate']), loss = loss_fn(), metrics = ['accuracy'])\n    elif optimizer == 'momentum':\n        model.compile(optimizer = SGD(learning_rate=config['learning_rate'], momentum = 0.9), loss = loss_fn(), metrics = ['accuracy'])\n    elif optimizer == 'rmsprop':\n        model.compile(optimizer = RMSprop(learning_rate=config['learning_rate']), loss = loss_fn(), metrics = ['accuracy'])\n    elif optimizer == 'nesterov':\n        model.compile(optimizer = SGD(learning_rate=config['learning_rate'], momentum = 0.9, nesterov = True), loss = loss_fn(), metrics = ['accuracy'])\n    elif optimizer == 'nadam':\n        model.compile(optimizer = Nadam(learning_rate=config['learning_rate']), loss = loss_fn(), metrics = ['accuracy'])\n    else:\n        model.compile(optimizer = SGD(learning_rate=config['learning_rate']), loss = loss_fn(), metrics = ['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:45.911779Z","iopub.execute_input":"2022-05-03T03:05:45.912268Z","iopub.status.idle":"2022-05-03T03:05:46.230857Z","shell.execute_reply.started":"2022-05-03T03:05:45.912214Z","shell.execute_reply":"2022-05-03T03:05:46.230102Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class customCallback(keras.callbacks.Callback):\n     # Custom class to provide callback after each epoch of training to calculate custom metrics for validation set with beam decoder\n    def __init__(self, val_enc_input, val_dec_target, beam_width=1, batch_size=64, attention=False):\n        self.beam_width = beam_width\n        self.validation_input = val_enc_input\n        self.validation_target = val_dec_target\n        self.batch_size = batch_size\n\n    def on_epoch_end(self, epoch, logs):\n        val_accuracy, val_exact_accuracy, val_loss = beam_decoder(self.model, self.validation_input, self.validation_target, max_decoder_seq_length, \n                                                                  target_token_index, reverse_target_char_index, self.beam_width, self.batch_size)\n\n        # Log them to reflect in WANDB callback and EarlyStopping\n        logs[\"val_accuracy\"] = val_accuracy\n        logs[\"val_exact_accuracy\"] = val_exact_accuracy\n        logs[\"val_loss\"] = val_loss             # Validation loss calculates categorical cross entropy loss\n\n        print(\"— val_loss: {:.3f} — val_accuracy: {:.3f} — val_exact_accuracy: {:.5f}\".format(val_loss, val_accuracy, val_exact_accuracy))","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:46.232318Z","iopub.execute_input":"2022-05-03T03:05:46.232594Z","iopub.status.idle":"2022-05-03T03:05:46.240213Z","shell.execute_reply.started":"2022-05-03T03:05:46.232555Z","shell.execute_reply":"2022-05-03T03:05:46.239490Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# model,history = model_train_util(config_)\n# model.save(\"s2s\")","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:46.241272Z","iopub.execute_input":"2022-05-03T03:05:46.242405Z","iopub.status.idle":"2022-05-03T03:05:46.263436Z","shell.execute_reply.started":"2022-05-03T03:05:46.242362Z","shell.execute_reply":"2022-05-03T03:05:46.262698Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Installing and logging into WANDB\n!pip install --upgrade wandb\n!wandb login b44266d937596fcef83bedbe7330d6cee108a277\n\nimport wandb\nfrom wandb.keras import WandbCallback","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:46.265062Z","iopub.execute_input":"2022-05-03T03:05:46.265705Z","iopub.status.idle":"2022-05-03T03:05:58.847442Z","shell.execute_reply.started":"2022-05-03T03:05:46.265663Z","shell.execute_reply":"2022-05-03T03:05:58.846584Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def model_train(config,iswandb=False):\n    wid = None\n    if iswandb:\n        wid = wandb.util.generate_id()\n        run = wandb.init(id = wid, project=\"cs6910_assignment_3\", entity=\"dlstack\", reinit=True, config=config)\n        wandb.run.name = f\"ies_{config['input_embedding_size']}_nenc_{config['num_enc_layers']}_ndec_{config['num_dec_layers']}_cell_{config['cell_type']}_drop_{config['dropout']}_rdrop_{config['r_dropout']}\"\n        wandb.run.name += f\"_hs_{config['hidden_layer_size']}_B_{config['beam_width']}\"\n        wandb.run.save()\n        print(wandb.run.name)\n\n    model = model_train_util(config)\n    if iswandb:\n        call_list = [customCallback(val_encoder_input,val_decoder_target,beam_width=config['beam_width'],batch_size=config['batch_size']),WandbCallback(monitor='val_accuracy'),EarlyStopping(monitor='val_accuracy',patience=4)]\n    else:\n        call_list = [customCallback(val_encoder_input,val_decoder_target,beam_width=config['beam_width'],batch_size=config['batch_size']),EarlyStopping(monitor='val_accuracy',patience=4)]\n    history = model.fit(\n        [train_encoder_input,train_decoder_input],\n        train_decoder_target,\n        batch_size=config['batch_size'],\n        verbose = 1,\n        epochs=config['epochs'],\n        callbacks = call_list\n    )    \n    if iswandb:\n        run.finish()\n\n    return model, history,config, wid","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:58.849191Z","iopub.execute_input":"2022-05-03T03:05:58.849472Z","iopub.status.idle":"2022-05-03T03:05:58.861900Z","shell.execute_reply.started":"2022-05-03T03:05:58.849434Z","shell.execute_reply":"2022-05-03T03:05:58.861163Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def wandb_sweep():\n    # Wrapper function to call the model_train() function for sweeping with different hyperparameters\n\n    # Initialize a new wandb run\n    run = wandb.init(config=config_, reinit=True)\n\n    # Config is a variable that holds and saves hyperparameters and inputs\n    config = wandb.config\n\n    wandb.run.name = f'ies_{config.input_embedding_size}_nenc_{config.num_enc_layers}_ndec_{config.num_dec_layers}_cell_{config.cell_type}_drop_{config.dropout}_rdrop_{config.r_dropout}'\n    wandb.run.name += f'_hs_{config.hidden_layer_size}_B_{config.beam_width}'\n    wandb.run.save()\n    print(wandb.run.name)\n\n    model, *_ = model_train(config, iswandb=True)\n    run.finish()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:58.864020Z","iopub.execute_input":"2022-05-03T03:05:58.866263Z","iopub.status.idle":"2022-05-03T03:05:58.872878Z","shell.execute_reply.started":"2022-05-03T03:05:58.866221Z","shell.execute_reply":"2022-05-03T03:05:58.872207Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def make_inference_model(model):\n    # Calculating number of layers in encoder and decoder\n    num_enc_layers, num_dec_layers = 0, 0\n    for layer in model.layers:\n        num_enc_layers += layer.name.startswith('encoder')\n        num_dec_layers += layer.name.startswith('decoder')\n\n    # Encoder input\n    encoder_input = model.input[0]      # Input_1\n    # Encoder cell final layer\n    encoder_cell = model.get_layer(\"encoder_\"+str(num_enc_layers))\n    encoder_type = encoder_cell.__class__.__name__\n    encoder_seq, *encoder_state = encoder_cell.output\n    # Encoder model\n    encoder_model = keras.Model(encoder_input, encoder_state)\n\n    # Decoder input\n    decoder_input = model.input[1]      # Input_2\n    decoder_input_embedding = model.get_layer(\"embedding_2\")(decoder_input)\n    decoder_sequences = decoder_input_embedding\n    # Inputs to decoder layers' initial states\n    decoder_states, decoder_state_inputs = [], []\n    for i in range(1, num_dec_layers+1):\n        if encoder_type == 'LSTM':\n            decoder_state_input = [Input(shape=(encoder_state[0].shape[1],), name=\"input_\"+str(2*i+1)), \n                                   Input(shape=(encoder_state[1].shape[1],), name=\"input_\"+str(2*i+2))]\n        else:\n            decoder_state_input = [Input(shape=(encoder_state[0].shape[1],), name=\"input_\"+str(i+2))]\n\n        decoder_cell = model.get_layer(\"decoder_\"+str(i))\n        decoder_sequences, *decoder_state = decoder_cell(decoder_sequences, initial_state=decoder_state_input)\n        decoder_states += decoder_state\n        decoder_state_inputs += decoder_state_input\n\n    # Softmax FC layer\n    decoder_dense = model.get_layer(\"dense_1\")\n    decoder_dense_output = decoder_dense(decoder_sequences)\n\n    # Decoder model\n    decoder_model = keras.Model(\n        [decoder_input] + decoder_state_inputs, [decoder_dense_output] + decoder_states\n    )\n\n    return encoder_model, decoder_model, num_enc_layers, num_dec_layers\n\n\ndef num_to_word(num_encoded, token_index, reverse_char_index = None):\n    # Function to return the predictions after cutting the END_CHAR and BLANK_CHAR s at the end.\n    # If char_dec == None, the predictions are in the form of decoded string, otherwise as list of integers\n    num_samples = len(num_encoded) if type(num_encoded) is list else num_encoded.shape[0]\n    predicted_words = ['' for t in range(num_samples)]\n    for i, encode in enumerate(num_encoded):\n        for l in encode:\n            # Stop word : '\\n'\n            if l == token_index['\\n']:\n                break\n            predicted_words[i] += reverse_char_index[l] if reverse_char_index is not None else str(l)\n    \n    return predicted_words","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-03T03:05:58.874189Z","iopub.execute_input":"2022-05-03T03:05:58.874902Z","iopub.status.idle":"2022-05-03T03:05:58.889697Z","shell.execute_reply.started":"2022-05-03T03:05:58.874816Z","shell.execute_reply":"2022-05-03T03:05:58.888957Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def beam_decoder_util(model,input_sequences,max_decoder_seq_length,B=1,target_sequences=None,start_char=0,batch_size=64):\n    encoder_model,decoder_model,num_enc_layers,num_dec_layers=make_inference_model(model)\n    encoder_output = encoder_model.predict(input_sequences,batch_size=batch_size)\n    encoder_output = encoder_output if type(encoder_output) is list else [encoder_output]\n    \n    num_samples = input_sequences.shape[0]\n    \n    outputs_fn = np.zeros((num_samples,B,max_decoder_seq_length),dtype=np.int32)\n    \n    errors_fn = np.zeros((num_samples,B))\n    \n    decoder_b_inputs = np.zeros((num_samples,1,1))\n    decoder_b_inputs[:, :, 0] = start_char\n    \n    decoder_b_out = [[(0, [])] for t in range(num_samples)]\n    errors = [[0] for t in range(num_samples)]\n    \n    states = [encoder_output*num_dec_layers]\n    \n    for idx in range(max_decoder_seq_length):\n        all_b_beams = [[] for t in range(num_samples)]\n        all_decoder_states = [[] for t in range(num_samples)]\n        all_errors = [[] for t in range(num_samples)]\n        for b in range(len(decoder_b_out[0])):\n            decoder_output, *decoder_states = decoder_model.predict([decoder_b_inputs[:,b]] + states[b],batch_size=batch_size)\n            top_b = np.argsort(decoder_output[:,-1,:],axis=-1)[:,-B:]\n            for n in range(num_samples):\n                all_b_beams[n]+= [(decoder_b_out[n][b][0] + np.log(decoder_output[n, -1, top_b[n][i]]),decoder_b_out[n][b][1] + [top_b[n][i]]) for i in range(B)]\n                if target_sequences is not None:\n                    all_errors[n] += [errors[n][b] - np.log(decoder_output[n,-1,target_sequences[n,idx]])]*B\n                all_decoder_states[n] += [[decoder_state[n:n+1] for decoder_state in decoder_states]] * B\n        sorted_index = list(range(len(all_b_beams[0])))\n        sorted_index = [sorted(sorted_index,key = lambda ix: all_b_beams[n][ix][0])[-B:][::-1] for n in range(num_samples)]\n        decoder_b_out = [[all_b_beams[n][index] for index in sorted_index[n]] for n in range(num_samples)]\n        \n        decoder_b_inputs = np.array([[all_b_beams[n][index][1][-1] for index in sorted_index[n]] for n in range(num_samples)])\n        \n        states = [all_decoder_states[0][index] for index in sorted_index[0]]\n        \n        for n in range(1,num_samples):\n            states = [[np.concatenate((states[i][j],all_decoder_states[n][index][j])) for j in range(len(all_decoder_states[n][index]))] for i,index in  enumerate(sorted_index[n])]\n        if target_sequences is not None:\n            errors = [[all_errors[n][index] for index in sorted_index[n]] for n in range(num_samples)]\n    outputs_fn = np.array([[decoder_b_out[n][i][1] for i in range(B)] for n in range(num_samples)])\n    if target_sequences is not None:\n        errors_fn = np.array(errors)/max_decoder_seq_length\n    return outputs_fn,errors_fn,np.array(states)\ndef calc_metrics(b_outputs, target_sequences,token_index,reverse_char_index,b_errors=None,exact_word=True,display=False):\n    matches = np.mean(b_outputs == target_sequences.reshape(target_sequences.shape[0],1,target_sequences.shape[1]),axis=-1)\n    best_b = np.argmax(matches,axis=-1)\n    best_index = (tuple(range(best_b.shape[0])),tuple(best_b))\n    accuracy = np.mean(matches[best_index])\n    b_predictions = list()\n    loss = None\n    if b_errors is not None:\n        loss = np.mean(b_errors[best_index])\n    if exact_word:\n        equal = [0] * b_outputs.shape[0]\n        true_out = num_to_word(target_sequences,token_index,reverse_char_index)\n        for b in range(b_outputs.shape[1]):\n            pred_out = num_to_word(b_outputs[:,b], token_index,reverse_char_index)\n            equal = [equal[i] or (pred_out[i] == true_out[i]) for i in range(b_outputs.shape[0])]\n            if display==True:\n                b_predictions.append(pred_out)\n        exact_accuracy = np.mean(equal)\n        if display==True:\n            return accuracy,exact_accuracy,loss,true_out,b_predictions\n        return accuracy,exact_accuracy,loss\n    return accuracy,loss\ndef beam_decoder(model,input_sequences,target_sequences_onehot,max_decoder_seq_length,token_index,reverse_char_index,B=1,model_batch_size=64,infer_batch_size=512,exact_word=True,return_outputs=False,return_states=False,display=False):\n    target_sequences = np.argmax(target_sequences_onehot,axis=-1)\n    b_outputs,b_errors,b_states=None,None,None\n    for i in range(0,input_sequences.shape[0],infer_batch_size):\n        tmp_b_outputs,tmp_b_errors,tmp_b_states = beam_decoder_util(model,input_sequences[i:i+infer_batch_size],max_decoder_seq_length,B,target_sequences[i:i+infer_batch_size],token_index['\\t'],model_batch_size)\n        \n        if b_errors is None:\n            b_outputs,b_errors,b_states = tmp_b_outputs,tmp_b_errors,tmp_b_states\n        else:\n            b_outputs = np.concatenate((b_outputs,tmp_b_outputs))\n            b_errors = np.concatenate((b_errors,tmp_b_errors))\n            b_states = np.concatenate((b_states,tmp_b_states),axis=2)\n    return_elements = []\n    if return_outputs:\n        return_elements += [b_outputs]\n    if return_states:\n        return_elements += [b_states]\n    if len(return_elements) > 0:\n        return calc_metrics(b_outputs,target_sequences,token_index,reverse_char_index,b_errors,exact_word,display) + tuple(return_elements)\n    return calc_metrics(b_outputs,target_sequences,target_token_index,reverse_char_index,b_errors,exact_word,display)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:58.891243Z","iopub.execute_input":"2022-05-03T03:05:58.891755Z","iopub.status.idle":"2022-05-03T03:05:58.925399Z","shell.execute_reply.started":"2022-05-03T03:05:58.891719Z","shell.execute_reply":"2022-05-03T03:05:58.924777Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# model, history,config, wid = model_train(config=config_,iswandb=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:58.930007Z","iopub.execute_input":"2022-05-03T03:05:58.930515Z","iopub.status.idle":"2022-05-03T03:05:58.936150Z","shell.execute_reply.started":"2022-05-03T03:05:58.930486Z","shell.execute_reply":"2022-05-03T03:05:58.935387Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# # Hyperparameter choices to sweep \n# sweep_config_1 = {\n#     'name': 'RNNs2s',\n#     'method': 'bayes',                   # Possible search : grid, random, bayes\n#     'metric': {\n#       'name': 'val_accuracy',\n#       'goal': 'maximize'   \n#     },\n#     'parameters': {\n#         'epochs':{\n#             'values':[10,15,20]\n#         },\n#         'learning_rate':{\n#             'values':[0.001,0.0001,0.005]\n#         },\n#         'optimizer':{\n#             'value':'adam'\n#         },\n#         'loss_function':{\n#           'value':'categorical_crossentropy'  \n#         },\n#         'input_embedding_size': {\n#             'values': [64,128,256]\n#         },\n#         'num_enc_layers': {\n#             'values': [2,3]\n#         },\n#         'num_dec_layers': {\n#             'values': [3,5]\n#         },\n#         'hidden_layer_size': {\n#             'values': [256,512,768]\n#         },\n#         'cell_type': {\n#             'values': ['GRU']\n#         },\n#         'dropout' :{\n#             'values': [0.20,0.30]\n#         },\n#         'r_dropout': {\n#             'values': [0.20,0.30]\n#         },\n#         'beam_width': {\n#             'values': [1,3,5]\n#         },\n#         'batch_size':{\n#             'values':[128,256]\n#         }\n#     }\n# }\n# sweep_id = wandb.sweep(sweep_config_1,entity='dlstack',project='cs6910_assignment_3')\n# wandb.agent(sweep_id,lambda:wandb_sweep(),count=10)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:58.937393Z","iopub.execute_input":"2022-05-03T03:05:58.937857Z","iopub.status.idle":"2022-05-03T03:05:58.945346Z","shell.execute_reply.started":"2022-05-03T03:05:58.937802Z","shell.execute_reply":"2022-05-03T03:05:58.944694Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Hyperparameter choices to sweep \nsweep_config_1 = {\n    'name': 'RNNs2s',\n    'method': 'bayes',                   # Possible search : grid, random, bayes\n    'metric': {\n      'name': 'val_accuracy',\n      'goal': 'maximize'   \n    },\n    'parameters': {\n        'epochs':{\n            'values':[10,15,20]\n        },\n        'learning_rate':{\n            'values':[1e-3,1e-4]\n        },\n        'optimizer':{\n            'value':'adam'\n        },\n        'loss_function':{\n          'value':'categorical_crossentropy'  \n        },\n        'input_embedding_size': {\n            'values': [32, 64, 128,256]\n        },\n        'num_enc_layers': {\n            'values': [2,3]\n        },\n        'num_dec_layers': {\n            'values': [2,3,5]\n        },\n        'hidden_layer_size': {\n            'values': [ 128,256,512,768]\n        },\n        'cell_type': {\n            'values': [ 'RNN','LSTM', 'GRU']\n        },\n        'dropout' :{\n            'values': [0.20,0.25,0.30]\n        },\n        'r_dropout':{\n          'values': [0.0,0.20,0.30]  \n        },\n        'beam_width': {\n            'values': [1, 3,5]\n        },\n        'batch_size':{\n            'values':[64,128,256]\n        }\n    }\n}\nsweep_id = wandb.sweep(sweep_config_1,entity='dlstack',project='cs6910_assignment_3')\nwandb.agent(sweep_id,lambda:wandb_sweep(),count=20)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:05:58.946304Z","iopub.execute_input":"2022-05-03T03:05:58.949520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameter choices to sweep \nsweep_config_1 = {\n    'name': 'RNNs2s',\n    'method': 'bayes',                   # Possible search : grid, random, bayes\n    'metric': {\n      'name': 'val_accuracy',\n      'goal': 'maximize'   \n    },\n    'parameters': {\n        'epochs':{\n            'values':[10,15,20]\n        },\n        'learning_rate':{\n            'values':[1e-3,1e-4]\n        },\n        'optimizer':{\n            'values':['rmsprop','adam','nadam','nesterov','sgd']\n        },\n        'loss_function':{\n          'value':'categorical_crossentropy'  \n        },\n        'input_embedding_size': {\n            'values': [32, 64,256]\n        },\n        'num_enc_layers': {\n            'values': [ 2, 3,4]\n        },\n        'num_dec_layers': {\n            'values': [ 2, 3,4]\n        },\n        'hidden_layer_size': {\n            'values': [64, 128, 256,512]\n        },\n        'cell_type': {\n            'values': ['RNN', 'LSTM', 'GRU']\n        },\n        'dropout' :{\n            'values': [0, 0.25, 0.3,0.4]\n        },\n        'r_dropout':{\n          'values':[0.0,0.1]  \n        },\n        'batch_size':{\n          'values':[64,128,256]  \n        },\n        'beam_width': {\n            'values': [1, 5]\n        }\n    }\n}\nsweep_id = wandb.sweep(sweep_config_1,entity='dlstack',project='cs6910_assignment_3')\nwandb.agent(sweep_id,lambda:wandb_sweep(),count=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_samples = print_samples(test_input_texts,true_out,pred_out,pred_scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model,show_shapes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}