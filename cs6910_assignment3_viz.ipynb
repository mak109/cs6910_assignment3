{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wget","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:29:06.182853Z","iopub.execute_input":"2022-05-03T05:29:06.183632Z","iopub.status.idle":"2022-05-03T05:29:15.104538Z","shell.execute_reply.started":"2022-05-03T05:29:06.183593Z","shell.execute_reply":"2022-05-03T05:29:15.103689Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Installing and logging into WANDB\n!pip install --upgrade wandb\n!wandb login b44266d937596fcef83bedbe7330d6cee108a277","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:29:15.107058Z","iopub.execute_input":"2022-05-03T05:29:15.107356Z","iopub.status.idle":"2022-05-03T05:29:26.590700Z","shell.execute_reply.started":"2022-05-03T05:29:15.107317Z","shell.execute_reply":"2022-05-03T05:29:26.589861Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import wget\nimport os\nimport tarfile\nimport csv\nimport matplotlib\nfrom zipfile import ZipFile","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:29:26.593953Z","iopub.execute_input":"2022-05-03T05:29:26.594169Z","iopub.status.idle":"2022-05-03T05:29:26.600612Z","shell.execute_reply.started":"2022-05-03T05:29:26.594142Z","shell.execute_reply":"2022-05-03T05:29:26.599928Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.font_manager import FontProperties\n# from __future__ import print_function\nfrom ipywidgets import interact, Layout, IntSlider\nfrom IPython.display import HTML as html_print\nfrom IPython.display import display\nimport random","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:29:26.603190Z","iopub.execute_input":"2022-05-03T05:29:26.603558Z","iopub.status.idle":"2022-05-03T05:29:26.694934Z","shell.execute_reply.started":"2022-05-03T05:29:26.603523Z","shell.execute_reply":"2022-05-03T05:29:26.694260Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.utils.vis_utils import plot_model","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:29:26.695930Z","iopub.execute_input":"2022-05-03T05:29:26.696150Z","iopub.status.idle":"2022-05-03T05:29:31.630044Z","shell.execute_reply.started":"2022-05-03T05:29:26.696119Z","shell.execute_reply":"2022-05-03T05:29:31.629290Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import wandb\nfrom wandb.keras import WandbCallback","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:29:31.631396Z","iopub.execute_input":"2022-05-03T05:29:31.631642Z","iopub.status.idle":"2022-05-03T05:29:32.369009Z","shell.execute_reply.started":"2022-05-03T05:29:31.631608Z","shell.execute_reply":"2022-05-03T05:29:32.368100Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from keras.layers import SimpleRNN,GRU,LSTM,Embedding,Input,Dense\nfrom keras.layers import Layer\nimport keras.backend as K","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:29:32.370871Z","iopub.execute_input":"2022-05-03T05:29:32.371124Z","iopub.status.idle":"2022-05-03T05:29:32.378076Z","shell.execute_reply.started":"2022-05-03T05:29:32.371085Z","shell.execute_reply":"2022-05-03T05:29:32.376988Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"filename = 'dakshina_dataset_v1.0'\nurl = 'https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar'\nif not os.path.exists(filename+'.tar') and not os.path.exists(filename):\n    filename_tar = wget.download(url)\n    file = tarfile.open(filename_tar)\n    print('\\nExtracting files ....')\n    file.extractall()\n    file.close()\n    print('Done')\n    os.remove(filename_tar)\nelif not os.path.exists(filename):\n    filename_tar = filename + '.tar'\n    file = tarfile.open(filename_tar)\n    print('\\nExtracting files ....')\n    file.extractall()\n    file.close()\n    print('Done')\n    os.remove(filename_tar)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:29:32.379988Z","iopub.execute_input":"2022-05-03T05:29:32.380212Z","iopub.status.idle":"2022-05-03T05:29:50.249851Z","shell.execute_reply.started":"2022-05-03T05:29:32.380171Z","shell.execute_reply":"2022-05-03T05:29:50.248970Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"lang = 'bn'\ntrain_path =  filename+f\"/{lang}/lexicons/{lang}.translit.sampled.train.tsv\"\nval_path = filename+f\"/{lang}/lexicons/{lang}.translit.sampled.dev.tsv\"\ntest_path = filename+f\"/{lang}/lexicons/{lang}.translit.sampled.test.tsv\"","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:29:50.254612Z","iopub.execute_input":"2022-05-03T05:29:50.256911Z","iopub.status.idle":"2022-05-03T05:29:50.263463Z","shell.execute_reply.started":"2022-05-03T05:29:50.256865Z","shell.execute_reply":"2022-05-03T05:29:50.262834Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def read_data(path):\n    df = pd.read_csv(path,header=None,sep='\\t')\n    df.fillna(\"NaN\",inplace=True)\n    input_texts,target_texts = df[1].to_list(),df[0].to_list()\n    return input_texts,target_texts","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:29:50.268739Z","iopub.execute_input":"2022-05-03T05:29:50.279526Z","iopub.status.idle":"2022-05-03T05:29:51.417890Z","shell.execute_reply.started":"2022-05-03T05:29:50.279471Z","shell.execute_reply":"2022-05-03T05:29:51.417170Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def parse_text(texts):\n    characters = set()\n    for text in texts:\n        for c in text:\n            if c not in characters:\n                characters.add(c)\n    characters.add(' ')\n    return sorted(list(characters))","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:29:51.420141Z","iopub.execute_input":"2022-05-03T05:29:51.421465Z","iopub.status.idle":"2022-05-03T05:29:52.589261Z","shell.execute_reply.started":"2022-05-03T05:29:51.421424Z","shell.execute_reply":"2022-05-03T05:29:52.588198Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def start_end_pad(texts):\n    for i in range(len(texts)):\n        texts[i] = \"\\t\" + texts[i] + \"\\n\"\n    return texts","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:29:52.590844Z","iopub.execute_input":"2022-05-03T05:29:52.591089Z","iopub.status.idle":"2022-05-03T05:29:53.580731Z","shell.execute_reply.started":"2022-05-03T05:29:52.591059Z","shell.execute_reply":"2022-05-03T05:29:53.580006Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_input_texts,train_target_texts = read_data(train_path)\nval_input_texts,val_target_texts = read_data(val_path)\ntest_input_texts,test_target_texts = read_data(test_path)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:29:53.581923Z","iopub.execute_input":"2022-05-03T05:29:53.583833Z","iopub.status.idle":"2022-05-03T05:29:55.040724Z","shell.execute_reply.started":"2022-05-03T05:29:53.583791Z","shell.execute_reply":"2022-05-03T05:29:55.039951Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_target_texts = start_end_pad(train_target_texts)\nval_target_texts = start_end_pad(val_target_texts)\ntest_target_texts = start_end_pad(test_target_texts)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:29:55.042161Z","iopub.execute_input":"2022-05-03T05:29:55.042422Z","iopub.status.idle":"2022-05-03T05:29:56.713343Z","shell.execute_reply.started":"2022-05-03T05:29:55.042387Z","shell.execute_reply":"2022-05-03T05:29:56.712598Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"\n\nclass Attention(Layer):\n    \"\"\"\n    This Attention layer class code is used from : https://github.com/thushv89/attention_keras/blob/master/src/layers/attention.py\n    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n    There are three sets of weights introduced W_a, U_a, and V_a\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert isinstance(input_shape, list)\n        # Create a trainable weight variable for this layer.\n\n        self.W_a = self.add_weight(name='W_a',\n                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n                                   initializer='uniform',\n                                   trainable=True)\n        self.U_a = self.add_weight(name='U_a',\n                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n                                   initializer='uniform',\n                                   trainable=True)\n        self.V_a = self.add_weight(name='V_a',\n                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n                                   initializer='uniform',\n                                   trainable=True)\n\n        super(Attention, self).build(input_shape)  # Be sure to call this at the end\n\n    def call(self, inputs, verbose=False):\n        \"\"\"\n        inputs: [encoder_output_sequence, decoder_output_sequence]\n        \"\"\"\n        assert type(inputs) == list\n        encoder_out_seq, decoder_out_seq = inputs\n        if verbose:\n            print('encoder_out_seq>', encoder_out_seq.shape)\n            print('decoder_out_seq>', decoder_out_seq.shape)\n\n        def energy_step(inputs, states):\n            \"\"\" Step function for computing energy for a single decoder state\n            inputs: (batchsize * 1 * de_in_dim)\n            states: (batchsize * 1 * de_latent_dim)\n            \"\"\"\n\n            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n\n            \"\"\" Some parameters required for shaping tensors\"\"\"\n            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n            de_hidden = inputs.shape[-1]\n\n            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n            # <= batch size * en_seq_len * latent_dim\n            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n\n            \"\"\" Computing hj.Ua \"\"\"\n            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n            if verbose:\n                print('Ua.h>', U_a_dot_h.shape)\n\n            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n            # <= batch_size*en_seq_len, latent_dim\n            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n            if verbose:\n                print('Ws+Uh>', Ws_plus_Uh.shape)\n\n            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n            # <= batch_size, en_seq_len\n            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n            # <= batch_size, en_seq_len\n            e_i = K.softmax(e_i)\n\n            if verbose:\n                print('ei>', e_i.shape)\n\n            return e_i, [e_i]\n\n        def context_step(inputs, states):\n            \"\"\" Step function for computing ci using ei \"\"\"\n\n            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n\n            # <= batch_size, hidden_size\n            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n            if verbose:\n                print('ci>', c_i.shape)\n            return c_i, [c_i]\n\n        fake_state_c = K.sum(encoder_out_seq, axis=1)\n        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n\n        \"\"\" Computing energy outputs \"\"\"\n        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n        last_out, e_outputs, _ = K.rnn(\n            energy_step, decoder_out_seq, [fake_state_e],\n        )\n\n        \"\"\" Computing context vectors \"\"\"\n        last_out, c_outputs, _ = K.rnn(\n            context_step, e_outputs, [fake_state_c],\n        )\n\n        return c_outputs, e_outputs\n\n    def compute_output_shape(self, input_shape):\n        \"\"\" Outputs produced by the layer \"\"\"\n        return [\n            # (batch_size, decoder_timesteps, decoder_hid_layer_size)\n            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n            # (batch_size, decoder_timesteps, encoder_timesteps)\n            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n        ]","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:29:56.714859Z","iopub.execute_input":"2022-05-03T05:29:56.715099Z","iopub.status.idle":"2022-05-03T05:29:58.297138Z","shell.execute_reply.started":"2022-05-03T05:29:56.715066Z","shell.execute_reply":"2022-05-03T05:29:58.296351Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def enc_dec_tokens(train_input_texts,train_target_texts,val_input_texts,val_target_texts):\n    \n    input_characters = parse_text(train_input_texts + val_input_texts)\n    target_characters = parse_text(train_target_texts + val_target_texts)\n    num_encoder_tokens = len(input_characters)\n    num_decoder_tokens = len(target_characters)\n    max_encoder_seq_length = max([len(txt) for txt in train_input_texts + val_input_texts])\n    max_decoder_seq_length = max([len(txt) for txt in train_target_texts + val_target_texts])\n\n    print(\"Number of training samples:\", len(train_input_texts))\n    print(\"Number of validation samples:\", len(val_input_texts))\n    print(\"Number of unique input tokens:\", num_encoder_tokens)\n    print(\"Number of unique output tokens:\", num_decoder_tokens)\n    print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n    print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n    \n    input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n    target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n    \n    return input_token_index,target_token_index,max_encoder_seq_length,max_decoder_seq_length,num_encoder_tokens,num_decoder_tokens","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:29:58.298322Z","iopub.execute_input":"2022-05-03T05:29:58.298587Z","iopub.status.idle":"2022-05-03T05:29:58.383658Z","shell.execute_reply.started":"2022-05-03T05:29:58.298551Z","shell.execute_reply":"2022-05-03T05:29:58.382948Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def data_processing(input_texts,enc_length,input_token_index,num_encoder_tokens, target_texts,dec_length,target_token_index,num_decoder_tokens):\n    encoder_input_data = np.zeros(\n        (len(input_texts), enc_length), dtype=\"float32\"\n    )\n    decoder_input_data = np.zeros(\n            (len(input_texts), dec_length), dtype=\"float32\"\n        )\n    decoder_target_data = np.zeros(\n            (len(input_texts), dec_length, num_decoder_tokens), dtype=\"float32\"\n        )\n\n    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n        \n        for t, char in enumerate(input_text):\n            encoder_input_data[i, t] = input_token_index[char]\n        encoder_input_data[i, t + 1 :] = input_token_index[' ']\n        \n        for t, char in enumerate(target_text):\n                # decoder_target_data is ahead of decoder_input_data by one timestep\n            decoder_input_data[i, t] = target_token_index[char]\n            if t > 0:\n                    # decoder_target_data will be ahead by one timestep\n                    # and will not include the start character.\n                decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n        decoder_input_data[i, t + 1 :] = target_token_index[' ']\n        decoder_target_data[i, t:, target_token_index[' ']] = 1.0\n    return encoder_input_data,decoder_input_data,decoder_target_data","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:29:58.385136Z","iopub.execute_input":"2022-05-03T05:29:58.385738Z","iopub.status.idle":"2022-05-03T05:29:58.395881Z","shell.execute_reply.started":"2022-05-03T05:29:58.385702Z","shell.execute_reply":"2022-05-03T05:29:58.395153Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"input_token_index,target_token_index,max_encoder_seq_length,max_decoder_seq_length,num_encoder_tokens,num_decoder_tokens = enc_dec_tokens(train_input_texts,train_target_texts,val_input_texts,val_target_texts)\nreverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\nreverse_target_char_index = dict((i, char) for char, i in target_token_index.items())","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:29:58.398107Z","iopub.execute_input":"2022-05-03T05:29:58.398528Z","iopub.status.idle":"2022-05-03T05:29:58.559838Z","shell.execute_reply.started":"2022-05-03T05:29:58.398474Z","shell.execute_reply":"2022-05-03T05:29:58.558977Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_encoder_input,train_decoder_input,train_decoder_target = data_processing(train_input_texts,max_encoder_seq_length,input_token_index,num_encoder_tokens, train_target_texts,max_decoder_seq_length,target_token_index,num_decoder_tokens)\nval_encoder_input,val_decoder_input,val_decoder_target = data_processing(val_input_texts,max_encoder_seq_length,input_token_index,num_encoder_tokens, val_target_texts,max_decoder_seq_length,target_token_index,num_decoder_tokens)\ntest_encoder_input,test_decoder_input,test_decoder_target = data_processing(test_input_texts,max_encoder_seq_length,input_token_index,num_encoder_tokens, test_target_texts,max_decoder_seq_length,target_token_index,num_decoder_tokens)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:29:58.561090Z","iopub.execute_input":"2022-05-03T05:29:58.561354Z","iopub.status.idle":"2022-05-03T05:30:00.333968Z","shell.execute_reply.started":"2022-05-03T05:29:58.561319Z","shell.execute_reply":"2022-05-03T05:30:00.333224Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def make_inference_model_attn(model):\n    # Calculating number of layers in encoder and decoder\n    num_enc_layers, num_dec_layers = 0, 0\n    for layer in model.layers:\n        num_enc_layers += layer.name.startswith('encoder')\n        num_dec_layers += layer.name.startswith('decoder')\n\n    # Encoder input\n    encoder_input = model.input[0]      # Input_1\n    # Encoder cell final layer\n    encoder_cell = model.get_layer(\"encoder_\"+str(num_enc_layers))\n    encoder_type = encoder_cell.__class__.__name__\n    encoder_sequences, *encoder_state = encoder_cell.output\n    # Encoder model\n    encoder_model = keras.Model(encoder_input, encoder_state)\n\n    # Decoder input\n    decoder_input = model.input[1]      # Input_2\n    decoder_input_embedding = model.get_layer(\"embedding_2\")(decoder_input)\n    decoder_sequences = decoder_input_embedding\n    # Inputs to decoder layers' initial states\n    decoder_states, decoder_state_inputs = [], []\n    for i in range(1, num_dec_layers+1):\n        if encoder_type == 'LSTM':\n            decoder_state_input = [Input(shape=(encoder_state[0].shape[1],), name=\"input_\"+str(2*i+1)), \n                                   Input(shape=(encoder_state[1].shape[1],), name=\"input_\"+str(2*i+2))]\n        else:\n            decoder_state_input = [Input(shape=(encoder_state[0].shape[1],), name=\"input_\"+str(i+2))]\n\n        decoder_cell = model.get_layer(\"decoder_\"+str(i))\n        decoder_sequences, *decoder_state = decoder_cell(decoder_sequences, initial_state=decoder_state_input)\n        decoder_states += decoder_state\n        decoder_state_inputs += decoder_state_input\n    \n    attention_out,attention_scores = model.get_layer(\"attention_1\")([encoder_sequences,decoder_sequences])\n    \n    dense_concat_input = keras.layers.Concatenate(axis=-1,name='concat_layer_1')([decoder_sequences,attention_out])\n    # Softmax FC layer\n    decoder_dense = model.get_layer(\"dense_1\")\n    decoder_dense_output = decoder_dense(dense_concat_input)\n\n    # Decoder model\n    decoder_model = keras.Model(\n        [encoder_input,decoder_input] + decoder_state_inputs, [attention_scores,decoder_dense_output] + decoder_states\n    )\n\n    return encoder_model, decoder_model, num_enc_layers, num_dec_layers\n\ndef make_inference_model(model):\n    # Calculating number of layers in encoder and decoder\n    num_enc_layers, num_dec_layers = 0, 0\n    for layer in model.layers:\n        num_enc_layers += layer.name.startswith('encoder')\n        num_dec_layers += layer.name.startswith('decoder')\n\n    # Encoder input\n    encoder_input = model.input[0]      # Input_1\n    # Encoder cell final layer\n    encoder_cell = model.get_layer(\"encoder_\"+str(num_enc_layers))\n    encoder_type = encoder_cell.__class__.__name__\n    encoder_seq, *encoder_state = encoder_cell.output\n    # Encoder model\n    encoder_model = keras.Model(encoder_input, encoder_state)\n\n    # Decoder input\n    decoder_input = model.input[1]      # Input_2\n    decoder_input_embedding = model.get_layer(\"embedding_2\")(decoder_input)\n    decoder_sequences = decoder_input_embedding\n    # Inputs to decoder layers' initial states\n    decoder_states, decoder_state_inputs = [], []\n    for i in range(1, num_dec_layers+1):\n        if encoder_type == 'LSTM':\n            decoder_state_input = [Input(shape=(encoder_state[0].shape[1],), name=\"input_\"+str(2*i+1)), \n                                   Input(shape=(encoder_state[1].shape[1],), name=\"input_\"+str(2*i+2))]\n        else:\n            decoder_state_input = [Input(shape=(encoder_state[0].shape[1],), name=\"input_\"+str(i+2))]\n\n        decoder_cell = model.get_layer(\"decoder_\"+str(i))\n        decoder_sequences, *decoder_state = decoder_cell(decoder_sequences, initial_state=decoder_state_input)\n        decoder_states += decoder_state\n        decoder_state_inputs += decoder_state_input\n\n    # Softmax FC layer\n    decoder_dense = model.get_layer(\"dense_1\")\n    decoder_dense_output = decoder_dense(decoder_sequences)\n\n    # Decoder model\n    decoder_model = keras.Model(\n        [decoder_input] + decoder_state_inputs, [decoder_dense_output] + decoder_states\n    )\n\n    return encoder_model, decoder_model, num_enc_layers, num_dec_layers\n\n\ndef num_to_word(num_encoded, token_index, reverse_char_index = None):\n    # Function to return the predictions after cutting the END_CHAR and BLANK_CHAR s at the end.\n    # If char_dec == None, the predictions are in the form of decoded string, otherwise as list of integers\n    num_samples = len(num_encoded) if type(num_encoded) is list else num_encoded.shape[0]\n    predicted_words = ['' for t in range(num_samples)]\n    for i, encode in enumerate(num_encoded):\n        for l in encode:\n            # Stop word : '\\n'\n            if l == token_index['\\n']:\n                break\n            predicted_words[i] += reverse_char_index[l] if reverse_char_index is not None else str(l)\n    \n    return predicted_words","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:30:00.335434Z","iopub.execute_input":"2022-05-03T05:30:00.335677Z","iopub.status.idle":"2022-05-03T05:30:00.360333Z","shell.execute_reply.started":"2022-05-03T05:30:00.335644Z","shell.execute_reply":"2022-05-03T05:30:00.359572Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def beam_decoder_util(model,input_sequences,max_decoder_seq_length,B=1,target_sequences=None,start_char=0,batch_size=64,attention=False):\n    if attention:\n        encoder_model,decoder_model,num_enc_layers,num_dec_layers=make_inference_model_attn(model)\n    else:\n        encoder_model,decoder_model,num_enc_layers,num_dec_layers=make_inference_model(model)\n    encoder_output = encoder_model.predict(input_sequences,batch_size=batch_size)\n    encoder_output = encoder_output if type(encoder_output) is list else [encoder_output]\n    \n    num_samples = input_sequences.shape[0]\n    \n    outputs_fn = np.zeros((num_samples,B,max_decoder_seq_length),dtype=np.int32)\n    \n    errors_fn = np.zeros((num_samples,B))\n    \n    decoder_b_inputs = np.zeros((num_samples,1,1))\n    decoder_b_inputs[:, :, 0] = start_char\n    \n    decoder_b_out = [[(0, [])] for t in range(num_samples)]\n    errors = [[0] for t in range(num_samples)]\n    \n    states = [encoder_output*num_dec_layers]\n    if attention:\n        attn_b_scores = [[None] for t in range(num_samples)]\n    for idx in range(max_decoder_seq_length):\n        all_b_beams = [[] for t in range(num_samples)]\n        all_decoder_states = [[] for t in range(num_samples)]\n        all_errors = [[] for t in range(num_samples)]\n        if attention:\n            all_attn_scores = [[] for t in range(num_samples)]\n        for b in range(len(decoder_b_out[0])):\n            if attention:\n                attn_scores,decoder_output, *decoder_states = decoder_model.predict([input_sequences,decoder_b_inputs[:,b]] + states[b],batch_size=batch_size)\n            else:\n                decoder_output, *decoder_states = decoder_model.predict([decoder_b_inputs[:,b]] + states[b],batch_size=batch_size)\n            top_b = np.argsort(decoder_output[:,-1,:],axis=-1)[:,-B:]\n            for n in range(num_samples):\n                all_b_beams[n]+= [(decoder_b_out[n][b][0] + np.log(decoder_output[n, -1, top_b[n][i]]),decoder_b_out[n][b][1] + [top_b[n][i]]) for i in range(B)]\n                if attention:\n                    all_attn_scores[n] += [attn_scores[n]]*B if attn_b_scores[n][b] is None else [np.concatenate((attn_b_scores[n][b],attn_scores[n]),axis=0)]*B\n                if target_sequences is not None:\n                    all_errors[n] += [errors[n][b] - np.log(decoder_output[n,-1,target_sequences[n,idx]])]*B\n                all_decoder_states[n] += [[decoder_state[n:n+1] for decoder_state in decoder_states]] * B\n        sorted_index = list(range(len(all_b_beams[0])))\n        sorted_index = [sorted(sorted_index,key = lambda ix: all_b_beams[n][ix][0])[-B:][::-1] for n in range(num_samples)]\n        decoder_b_out = [[all_b_beams[n][index] for index in sorted_index[n]] for n in range(num_samples)]\n        decoder_b_inputs = np.array([[all_b_beams[n][index][1][-1] for index in sorted_index[n]] for n in range(num_samples)])\n        \n        states = [all_decoder_states[0][index] for index in sorted_index[0]]\n        \n        for n in range(1,num_samples):\n            states = [[np.concatenate((states[i][j],all_decoder_states[n][index][j])) for j in range(len(all_decoder_states[n][index]))] for i,index in  enumerate(sorted_index[n])]\n        if attention:\n            attn_b_scores = [[all_attn_scores[n][index] for index in sorted_index[n]] for n in range(num_samples)]    \n        if target_sequences is not None:\n            errors = [[all_errors[n][index] for index in sorted_index[n]] for n in range(num_samples)]\n    outputs_fn = np.array([[decoder_b_out[n][i][1] for i in range(B)] for n in range(num_samples)])\n    if target_sequences is not None:\n        errors_fn = np.array(errors)/max_decoder_seq_length\n        if attention:\n            return outputs_fn,errors_fn,np.array(states),np.array(attn_b_scores)\n        return outputs_fn,errors_fn,np.array(states)\ndef calc_metrics(b_outputs, target_sequences,token_index,reverse_char_index,b_errors=None,exact_word=True,display=False):\n    matches = np.mean(b_outputs == target_sequences.reshape((target_sequences.shape[0],1,target_sequences.shape[1])),axis=-1)\n    best_b = np.argmax(matches,axis=-1)\n    best_index = (tuple(range(best_b.shape[0])),tuple(best_b))\n    accuracy = np.mean(matches[best_index])\n    b_predictions = list()\n    loss = None\n    if b_errors is not None:\n        loss = np.mean(b_errors[best_index])\n    if exact_word:\n        equal = [0] * b_outputs.shape[0]\n        true_out = num_to_word(target_sequences,token_index,reverse_char_index)\n        for b in range(b_outputs.shape[1]):\n            pred_out = num_to_word(b_outputs[:,b], token_index,reverse_char_index)\n            equal = [equal[i] or (pred_out[i] == true_out[i]) for i in range(b_outputs.shape[0])]\n            if display==True:\n                b_predictions.append(pred_out)\n        exact_accuracy = np.mean(equal)\n        if display==True:\n            return accuracy,exact_accuracy,loss,true_out,b_predictions\n        return accuracy,exact_accuracy,loss\n    return accuracy,loss\ndef beam_decoder(model,input_sequences,target_sequences_onehot,max_decoder_seq_length,token_index,reverse_char_index,B=1,model_batch_size=64,infer_batch_size=512,exact_word=True,attention=False,return_outputs=False,return_states=False,return_attention=False,display=False):\n    target_sequences = np.argmax(target_sequences_onehot,axis=-1)\n    if attention:\n        b_outputs,b_errors,b_states,b_attention=None,None,None,None\n    else:\n        b_outputs,b_errors,b_states=None,None,None\n    for i in range(0,input_sequences.shape[0],infer_batch_size):\n        if attention:\n            tmp_b_outputs,tmp_b_errors,tmp_b_states,tmp_b_attention = beam_decoder_util(model,input_sequences[i:i+infer_batch_size],max_decoder_seq_length,B,target_sequences[i:i+infer_batch_size],token_index['\\t'],model_batch_size,attention=True)\n        else:\n            tmp_b_outputs,tmp_b_errors,tmp_b_states = beam_decoder_util(model,input_sequences[i:i+infer_batch_size],max_decoder_seq_length,B,target_sequences[i:i+infer_batch_size],token_index['\\t'],model_batch_size,attention=False)\n        if b_errors is None:\n            if attention:\n                b_outputs,b_errors,b_states,b_attention = tmp_b_outputs,tmp_b_errors,tmp_b_states,tmp_b_attention\n            else:\n                b_outputs,b_errors,b_states = tmp_b_outputs,tmp_b_errors,tmp_b_states\n        else:\n            if attention:\n                b_outputs = np.concatenate((b_outputs,tmp_b_outputs))\n                b_errors = np.concatenate((b_errors,tmp_b_errors))\n                b_states = np.concatenate((b_states,tmp_b_states),axis=2)\n                b_attention = np.concatenate((b_attention,tmp_b_attention))\n            else:\n                b_outputs = np.concatenate((b_outputs,tmp_b_outputs))\n                b_errors = np.concatenate((b_errors,tmp_b_errors))\n                b_states = np.concatenate((b_states,tmp_b_states),axis=2) \n    return_elements = []\n    if return_outputs:\n        return_elements += [b_outputs]\n    if return_states:\n        return_elements += [b_states]\n    if return_attention and attention:\n        return_elements += [b_attention]\n    if len(return_elements) > 0:\n        return calc_metrics(b_outputs,target_sequences,token_index,reverse_char_index,b_errors,exact_word,display) + tuple(return_elements)\n    return calc_metrics(b_outputs,target_sequences,target_token_index,reverse_char_index,b_errors,exact_word,display)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:30:00.361883Z","iopub.execute_input":"2022-05-03T05:30:00.362242Z","iopub.status.idle":"2022-05-03T05:30:00.407094Z","shell.execute_reply.started":"2022-05-03T05:30:00.362205Z","shell.execute_reply":"2022-05-03T05:30:00.406275Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def levenshtein(s1, s2):\n    # Function to calculate levenshtein distance between two sequences usign Dynamic Programming\n    m, n = len(s1)+1, len(s2)+1\n    # Initialisation\n    dp = np.zeros((m, n))\n    # Base case\n    dp[0,1:] = np.arange(1,n)\n    dp[1:,0] = np.arange(1,m)\n\n    # Recursion\n    for i in range(1,m):\n        for j in range(1,n):\n            if s1[i-1] == s2[j-1]:\n                dp[i,j] = min(dp[i-1,j-1], dp[i-1,j]+1, dp[i,j-1]+1)\n            else:\n                dp[i,j] = min(dp[i,j-1], dp[i-1,j], dp[i-1,j-1]) + 1\n    \n    return dp[m-1,n-1]","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-03T05:30:00.408544Z","iopub.execute_input":"2022-05-03T05:30:00.408859Z","iopub.status.idle":"2022-05-03T05:30:00.419903Z","shell.execute_reply.started":"2022-05-03T05:30:00.408825Z","shell.execute_reply":"2022-05-03T05:30:00.419100Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"\ndef test_model(run_id,test_encoder_input,test_decoder_target,max_decoder_seq_length,target_token_index,reverse_target_char_index,attention=False,save_pred=False,test_input_texts=None):\n    api = wandb.Api()\n    r = api.run('dlstack/cs6910_assignment_3/'+run_id)\n#     print(r.config)\n    config = r.config['_items'] if '_items' in r.config.keys() else r.config\n#     print(config)\n    model_file = r.file('model-best.h5').download(replace=True)\n    if attention:\n        model = keras.models.load_model(model_file.name,custom_objects={'Attention':Attention})\n    else:\n        model = keras.models.load_model(model_file.name)\n    \n    num_samples,batch_size,B = test_encoder_input.shape[0],config['batch_size'],config['beam_width']\n    if attention:\n        acc, exact_B_acc, loss, outputs,attention_scores = beam_decoder(model, test_encoder_input, test_decoder_target, max_decoder_seq_length, \n                                                                target_token_index, reverse_target_char_index,B, batch_size,attention=True,\n                                                                return_outputs=True,return_attention=True)\n    else:\n        acc, exact_B_acc, loss, outputs = beam_decoder(model, test_encoder_input, test_decoder_target, max_decoder_seq_length, \n                                                                target_token_index, reverse_target_char_index,B, batch_size,attention=False,\n                                                                return_outputs=True,return_attention=False)    \n    print(f'Test accuracy (using exact word match with beam width = {B}) : {exact_B_acc*100:.2f}%')\n    \n    test_target = np.argmax(test_decoder_target, axis=-1)\n    true_out = num_to_word(test_target, target_token_index, reverse_target_char_index)\n    pred_out = [[] for t in range(num_samples)]\n    pred_scores = [[] for t in range(num_samples)]\n    for b in range(B):\n        pred = num_to_word(outputs[:,b], target_token_index, reverse_target_char_index)\n        pred_out = [pred_out[n] + [pred[n]] for n in range(num_samples)]\n        pred_scores = [pred_scores[n] + [levenshtein(pred[n], true_out[n])] for n in range(num_samples)]\n\n    equal = [pred_out[n][0] == true_out[n] for n in range(num_samples)]\n    exact_acc = np.mean(equal)\n\n    print(f'Test accuracy (using exact word match of the first prediction) : {exact_acc*100:.2f}%')\n    print('\\n')\n    save_pred = True\n    if save_pred:\n        # We write the input and top K outputs in decreasing order of probabilities to the file\n        pred_file_name = 'predictions_attention.csv' if attention else 'predictions.csv'\n        with open(pred_file_name, 'w', newline='') as file:\n            writer = csv.writer(file)\n            writer.writerow([\"Input\"] + [\"Prediction_\"+str(b+1) for b in range(B)])\n            for n in range(num_samples):\n                writer.writerow([test_input_texts[n]] + [pred_out[n][b] for b in range(B)])\n    if attention:\n        return acc, exact_B_acc, exact_acc, loss, true_out, pred_out, pred_scores, attention_scores, model\n    return acc, exact_B_acc, exact_acc, loss, true_out, pred_out, pred_scores, model","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:37:19.153208Z","iopub.execute_input":"2022-05-03T05:37:19.153778Z","iopub.status.idle":"2022-05-03T05:37:19.170078Z","shell.execute_reply.started":"2022-05-03T05:37:19.153743Z","shell.execute_reply":"2022-05-03T05:37:19.169078Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"\ndef get_clr(value, cmap=None):\n    # Function to get appropriate color for a value between 0 and 1 from the default blue to red hard-coded colors or a matplotlib cmap \n    colors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8',\n        '#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n        '#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n        '#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n    if cmap is not None:\n        rgba = matplotlib.cm.get_cmap(cmap)(value,alpha=None,bytes=True)\n        return 'rgb'+str(rgba[:-1])\n    value = min(int((value * 100) / 5), 19)\n    return colors[value]","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:32:04.175190Z","iopub.execute_input":"2022-05-03T05:32:04.175791Z","iopub.status.idle":"2022-05-03T05:32:04.181903Z","shell.execute_reply.started":"2022-05-03T05:32:04.175750Z","shell.execute_reply":"2022-05-03T05:32:04.181022Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"\ndef print_samples(inputs, true_output, pred_output, pred_scores, random_seq=None,cmap=None):\n    '''\n    Function to print sample outputs in a neat format\n    Arguments :\n        inputs -- input words\n        true_output -- true output as words\n        pred_output -- K predicted output words\n        pred_scores -- levenshtein distance for the predictions to the true output\n        random_seq -- list of indices from the dataset passed for which the sample outputs are to be printed (If None, random 10 samples will be chosen)\n    Returns :\n        random_seq -- the list of indices for which sample outputs are printed\n    '''\n    num_samples = len(true_output)\n    if random_seq is None:\n        random_seq = random.sample(range(num_samples),10)\n    print('-'*20 + f' Top {len(pred_scores[0])} predictions in decreasing order of probabilities for 10 random samples ' + '-'*20)\n    print('')\n    for i in random_seq:\n        K = len(pred_scores[i])\n        html_str = '''\n        <table style=\"border:2px solid black; border-collapse:collapse\">\n        <caption> <strong>INPUT :</strong> {} &emsp; | &emsp; <strong> TRUE OUTPUT : </strong> {} </caption>\n        <tr>\n        <th scope=\"row\" style=\"border:1px solid black;padding:10px;text-align:left\"> Top {} Predictions </th>\n        '''.format(inputs[i], true_output[i], K)\n        for k in range(K):\n            html_str += '''\n            <td style=\"color:#000;background-color:{};border:1px solid black;padding:10px\"> {} </td>\n            '''.format(get_clr(pred_scores[i][k]/5,cmap), pred_output[i][k])\n        html_str += '''\n        </tr>\n        <tr>\n        <th scope=\"row\" style=\"border:1px solid black;padding:10px;text-align:left\"> Levenshtein distance (to true output) &emsp; </th>\n        '''\n        for k in range(K):\n            html_str += '''\n            <td style=\"border:1px solid black;padding:10px\"> {} </td>\n            '''.format(pred_scores[i][k])\n        html_str += '''\n        </tr>\n        </table>\n        '''\n        display(html_print(html_str))\n        print('\\n\\n')\n    \n    return random_seq","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:32:05.658358Z","iopub.execute_input":"2022-05-03T05:32:05.659026Z","iopub.status.idle":"2022-05-03T05:32:05.667989Z","shell.execute_reply.started":"2022-05-03T05:32:05.658988Z","shell.execute_reply":"2022-05-03T05:32:05.667243Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"\n\nbest_run_id = \"nrd2ctiz\"\nacc, exact_B_acc, exact_acc, loss, true_out, pred_out, pred_scores,model = test_model(best_run_id,test_encoder_input,test_decoder_target,max_decoder_seq_length,target_token_index,reverse_target_char_index,save_pred=True,test_input_texts=test_input_texts)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:37:27.733594Z","iopub.execute_input":"2022-05-03T05:37:27.733885Z","iopub.status.idle":"2022-05-03T05:40:43.267953Z","shell.execute_reply.started":"2022-05-03T05:37:27.733856Z","shell.execute_reply":"2022-05-03T05:40:43.267143Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"random_samples = print_samples(test_input_texts,true_out,pred_out,pred_scores)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:41:13.569785Z","iopub.execute_input":"2022-05-03T05:41:13.570039Z","iopub.status.idle":"2022-05-03T05:41:13.602617Z","shell.execute_reply.started":"2022-05-03T05:41:13.570011Z","shell.execute_reply":"2022-05-03T05:41:13.601930Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"plot_model(model,show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:41:24.956914Z","iopub.execute_input":"2022-05-03T05:41:24.957165Z","iopub.status.idle":"2022-05-03T05:41:25.823257Z","shell.execute_reply.started":"2022-05-03T05:41:24.957138Z","shell.execute_reply":"2022-05-03T05:41:25.822385Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"best_attn_run_id = \"nkg32le7\"\nacc, exact_B_acc, exact_acc, loss, true_out, pred_out, pred_scores,attention_scores,model = test_model(best_attn_run_id,test_encoder_input,test_decoder_target,max_decoder_seq_length,target_token_index,reverse_target_char_index,attention=True,save_pred=True,test_input_texts=test_input_texts)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:41:56.094321Z","iopub.execute_input":"2022-05-03T05:41:56.094581Z","iopub.status.idle":"2022-05-03T05:45:01.520704Z","shell.execute_reply.started":"2022-05-03T05:41:56.094554Z","shell.execute_reply":"2022-05-03T05:45:01.519914Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"random_samples = print_samples(test_input_texts,true_out,pred_out,pred_scores)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:45:09.657700Z","iopub.execute_input":"2022-05-03T05:45:09.657959Z","iopub.status.idle":"2022-05-03T05:45:09.688519Z","shell.execute_reply.started":"2022-05-03T05:45:09.657929Z","shell.execute_reply":"2022-05-03T05:45:09.687813Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"plot_model(model,show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:45:15.164290Z","iopub.execute_input":"2022-05-03T05:45:15.165232Z","iopub.status.idle":"2022-05-03T05:45:15.379051Z","shell.execute_reply.started":"2022-05-03T05:45:15.165190Z","shell.execute_reply":"2022-05-03T05:45:15.378184Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"filename = 'Hind_Siliguri'\nurl = 'https://fonts.google.com/download?family=Hind%20Siliguri'\nif not os.path.exists(filename+'.zip') and not os.path.exists(filename):\n    filename_zip = wget.download(url)\n    with ZipFile(filename_zip, 'r') as z:\n        z.printdir()\n        print('\\nExtracting files ....')\n        z.extractall()\n        print('Done')\n    os.remove(filename_zip)\nelif not os.path.exists(filename):\n    filename_zip = filename + '.zip'\n    with ZipFile(filename_zip, 'r') as z:\n        z.printdir()\n        print('\\nExtracting files ....')\n        z.extractall()\n        print('Done')\n    os.remove(filename_zip)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:45:22.215985Z","iopub.execute_input":"2022-05-03T05:45:22.216311Z","iopub.status.idle":"2022-05-03T05:45:22.913482Z","shell.execute_reply.started":"2022-05-03T05:45:22.216260Z","shell.execute_reply":"2022-05-03T05:45:22.912609Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"\n\ndef plot_heatmaps(inputs,pred_out,pred_scores,attn_scores,wandb_log=False,random_seq=None,cmap='magma'):\n    num_samples = len(pred_out)\n    if random_seq is None:\n        random_seq = random.sample(range(num_samples),9)\n    random_seq = random_seq[:9]\n    \n    plt.close('all')\n    fig = plt.figure(figsize=(15,15))\n    fig,axes = plt.subplots(3,3, figsize=(15, 15),constrained_layout=True)\n    plt.suptitle('Attention Heatmaps',fontsize='x-large')\n    for i,ax in zip(random_seq,axes.flat):\n        K = len(pred_scores[i])\n        k = np.argmin(pred_scores[i])\n        X = attn_scores[i,k,:len(pred_out[i][k])+1,:len(inputs[i])+1].T\n        im = ax.imshow(X,vmin=0,vmax=1,cmap=cmap)\n        ax.set_xticks(range(len(pred_out[i][k])+1))\n        ax.set_xticklabels(list(pred_out[i][k])+['<end>'],fontproperties=FontProperties(fname='HindSiliguri-Medium.ttf'))\n        ax.set_yticks(range(len(inputs[i])+1))\n        ax.set_yticklabels(list(inputs[i])+['<end>'])\n        ax.set_ylabel(f'Encoder Input:{inputs[i]}')\n        ax.set_xlabel(f'Decoder Output:{pred_out[i][k]}',fontproperties=FontProperties(fname='HindSiliguri-Medium.ttf'))\n        ax.set_title(str(i) + r'$^{th}$ example of Test Set')\n        ax.set_aspect(\"equal\")\n        ax.grid(False)\n    fig.colorbar(im,ax=axes.ravel().tolist(),shrink=0.7)\n    if wandb_log:\n        run = wandb.init(project=\"cs6910_assignment_3\", entity=\"dlstack\", reinit=True)\n        wandb.log({'attention_heatmaps':fig})\n        run.finish()\n    plt.show()\n    return random_seq","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:45:26.761839Z","iopub.execute_input":"2022-05-03T05:45:26.762488Z","iopub.status.idle":"2022-05-03T05:45:26.774498Z","shell.execute_reply.started":"2022-05-03T05:45:26.762453Z","shell.execute_reply":"2022-05-03T05:45:26.773787Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"_ = plot_heatmaps(test_input_texts,pred_out,pred_scores,attention_scores,wandb_log=False,random_seq=random_samples)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:45:45.261615Z","iopub.execute_input":"2022-05-03T05:45:45.261903Z","iopub.status.idle":"2022-05-03T05:45:47.674252Z","shell.execute_reply.started":"2022-05-03T05:45:45.261857Z","shell.execute_reply":"2022-05-03T05:45:47.673571Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def cstr(s, color=None):\n      # Function to get text html element\n    if color is None:\n        return '''<text style=\"padding:2px; color:#C0C0C0\"> {} </text>'''.format(s)\n    return '''<text style=\"color:#000;background-color:{}; padding:2px; color:#FF6699\"> {} </text>'''.format(color, s)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:45:57.926150Z","iopub.execute_input":"2022-05-03T05:45:57.926766Z","iopub.status.idle":"2022-05-03T05:45:57.931672Z","shell.execute_reply.started":"2022-05-03T05:45:57.926725Z","shell.execute_reply":"2022-05-03T05:45:57.930654Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def print_connectivity(inputs, pred_out, pred_scores, attn_scores, dec_char_ind=0):\n    '''\n    Function to visualize attention for one index of decoder output of one sample\n    Arguments :\n        input -- sample input word\n        pred_out -- K predicted output words for the sample\n        pred_scores -- levenshtein distance for the predictions to the true output\n        attn_scores -- attention scores\n        dec_char_ind -- (default : 0) index of the character in decoder for which the visuzalization is to be done\n    Returns :\n        -- None --\n    '''\n    K = len(pred_scores)\n    print('-'*20 + f' Visualizing attention for Top {K} predictions (in decreasing order of probabilities) ' + '-'*20)\n    print('')\n    html_str = '''\n    <table style=\"border:2px solid black; border-collapse:collapse; font-size:1.5em\">\n    <caption> <strong>INPUT : </strong> {} </caption>\n    <tr>\n    <th style=\"border:1px solid black;padding:10px;text-align:center\"> Character in Prediction Focussed </th>\n    <th style=\"border:1px solid black;padding:10px;text-align:center\"> Attention Visualization </th>\n    </tr>\n    '''.format(inputs)\n    for k in range(K):  \n        char = pred_out[k][dec_char_ind] if dec_char_ind < len(pred_out[k]) else '&lt end &gt' if dec_char_ind == len(pred_out[k]) else '&lt blank &gt'\n        middle_char = pred_out[k][dec_char_ind] if dec_char_ind < len(pred_out[k]) else ''\n        end_str = pred_out[k][dec_char_ind+1:] if dec_char_ind < len(pred_out[k])-1 else ''\n        html_str += '''\n        <tr>\n        <td style=\"border:1px solid black;padding:10px;text-align:center\"> character at index {} of {}<span style=\"color: #FF1493\">{}</span>{} <br/> ({}) </td>\n        <td style=\"border:1px solid black;padding:10px;text-align:center\">\n        '''.format(dec_char_ind, pred_out[k][:dec_char_ind], middle_char, end_str, char)\n        for i,c in enumerate(inputs):\n            html_str += '''\n            {}\n            '''.format(cstr(c, get_clr(attn_scores[k,dec_char_ind,i], 'YlGnBu')))\n        html_str += '''\n        </td>\n        </tr>\n        '''\n    html_str += '''\n    </table>\n    '''\n    display(html_print(html_str))","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:46:05.287204Z","iopub.execute_input":"2022-05-03T05:46:05.287949Z","iopub.status.idle":"2022-05-03T05:46:05.298346Z","shell.execute_reply.started":"2022-05-03T05:46:05.287912Z","shell.execute_reply":"2022-05-03T05:46:05.297539Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"def visualize_attention(sample_ind=0, dec_char_ind=0):\n    # Function to visualize the importance of encoder input characters to the (dec_char_ind)th character of the output,\n    # for the (sample_ind)th sample in the test data\n    print_connectivity(test_input_texts[sample_ind], pred_out[sample_ind], pred_scores[sample_ind], attention_scores[sample_ind], dec_char_ind)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:46:09.457253Z","iopub.execute_input":"2022-05-03T05:46:09.457956Z","iopub.status.idle":"2022-05-03T05:46:09.464063Z","shell.execute_reply.started":"2022-05-03T05:46:09.457917Z","shell.execute_reply":"2022-05-03T05:46:09.463255Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"\n\n# Question 6 - visualizing attention\n# One can directly use visualize_attention(sample_ind, decoder_index) to get the result if interaction isn't needed, \n# but uncommenting below code is easier to use and offers a good way to choose the sample index and decoder index, and seeing the attention for K decoder predictons\n######################### UNCOMMENT BELOW CODE TO RUN ##########################\n\n@interact(sample_ind = IntSlider(min=0, max=len(test_input_texts)-1, step=1, value=10, layout=Layout(width='800px')))\ndef f(sample_ind):\n    print(f'Input : {test_input_texts[sample_ind]}')\n    print(f'Top {len(pred_out[sample_ind])} predictions : ')\n    mx_len = 0\n    for pred in pred_out[sample_ind]:\n        print(pred)\n        mx_len = max(mx_len, len(pred))\n    \n    @interact(character_ind = IntSlider(min=0, max=mx_len-1, step=1, value=0))\n    def g(character_ind):\n        visualize_attention(sample_ind, character_ind)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:46:11.690121Z","iopub.execute_input":"2022-05-03T05:46:11.690389Z","iopub.status.idle":"2022-05-03T05:46:11.763702Z","shell.execute_reply.started":"2022-05-03T05:46:11.690358Z","shell.execute_reply":"2022-05-03T05:46:11.763016Z"},"trusted":true},"execution_count":50,"outputs":[]}]}